import os
import json
import glob
import subprocess
from typing import Dict, Any, List, Optional
from pathlib import Path
from langchain_core.tools import tool
from pydantic.v1 import BaseModel, Field

# ============================================================================
# è¾“å…¥æ¨¡å‹å®šä¹‰ - éµå¾ªæ¥å£éš”ç¦»åŸåˆ™
# ============================================================================

class DirectoryQueryArgs(BaseModel):
    """ç›®å½•æŸ¥è¯¢å‚æ•°æ¨¡å‹"""
    directory_path: str = Field(description="è¦æŸ¥è¯¢çš„ç›®å½•è·¯å¾„")

class FastqQueryArgs(BaseModel):
    """FASTQæ–‡ä»¶æŸ¥è¯¢å‚æ•°æ¨¡å‹"""
    directory_path: str = Field(description="åŒ…å«FASTQæ–‡ä»¶çš„ç›®å½•è·¯å¾„")
    pattern: str = Field(default="*.fastq*", description="æ–‡ä»¶åŒ¹é…æ¨¡å¼")

class GenomeQueryArgs(BaseModel):
    """åŸºå› ç»„æŸ¥è¯¢å‚æ•°æ¨¡å‹"""
    genome_name: Optional[str] = Field(default=None, description="åŸºå› ç»„åç§°ï¼Œå¦‚hg38ã€mm39ç­‰ã€‚å¦‚æœä¸æä¾›ï¼Œå°†è¿”å›æ‰€æœ‰åŸºå› ç»„ä¿¡æ¯")
    config_path: str = Field(default="config/genomes.json", description="åŸºå› ç»„é…ç½®æ–‡ä»¶è·¯å¾„")

class NextflowConfigArgs(BaseModel):
    """Nextflowé…ç½®å‚æ•°æ¨¡å‹"""
    param_name: str = Field(description="å‚æ•°åç§°")
    param_value: Any = Field(description="å‚æ•°å€¼")

class BatchConfigArgs(BaseModel):
    """æ‰¹é‡é…ç½®æ›´æ–°å‚æ•°æ¨¡å‹"""
    config_updates: Dict[str, Any] = Field(description="è¦æ›´æ–°çš„é…ç½®å­—å…¸")

class ModeSwitch(BaseModel):
    """æ¨¡å¼åˆ‡æ¢å‚æ•°æ¨¡å‹"""
    target_mode: str = Field(description="ç›®æ ‡æ¨¡å¼ï¼šplanæˆ–execute")
    reason: str = Field(description="åˆ‡æ¢åŸå› ")

class ExecutionArgs(BaseModel):
    """æ‰§è¡Œå‚æ•°æ¨¡å‹"""
    config_path: str = Field(default="config/nextflow.config", description="nextflowé…ç½®æ–‡ä»¶è·¯å¾„")
    work_dir: str = Field(default="./work", description="å·¥ä½œç›®å½•")

class TreeListArgs(BaseModel):
    """ç›®å½•æ ‘åˆ—è¡¨å‚æ•°æ¨¡å‹"""
    directory_path: str = Field(description="è¦æŸ¥è¯¢çš„ç›®å½•è·¯å¾„")
    max_depth: Optional[int] = Field(default=None, description="æœ€å¤§é€’å½’æ·±åº¦ï¼ŒNoneè¡¨ç¤ºæ— é™åˆ¶")
    file_pattern: Optional[str] = Field(default=None, description="æ–‡ä»¶åŒ¹é…æ¨¡å¼ï¼Œå¦‚*.txt")
    show_only_files: bool = Field(default=False, description="æ˜¯å¦åªæ˜¾ç¤ºæ–‡ä»¶ï¼Œä¸æ˜¾ç¤ºç›®å½•")
    output_format: str = Field(default="tree", description="è¾“å‡ºæ ¼å¼ï¼Œå¯é€‰'tree'ï¼ˆæ ‘å½¢ç»“æ„ï¼‰æˆ–'list'ï¼ˆç®€å•åˆ—è¡¨ï¼‰")

# ============================================================================
# ä¿¡æ¯æŸ¥è¯¢å·¥å…·ç»„ - éµå¾ªå•ä¸€èŒè´£åŸåˆ™
# ============================================================================

@tool(args_schema=DirectoryQueryArgs)
def list_directory_contents(directory_path: str) -> str:
    """
    åˆ—å‡ºæŒ‡å®šç›®å½•çš„å†…å®¹
    
    åº”ç”¨KISSåŸåˆ™ï¼šç®€å•ç›´æ¥çš„ç›®å½•åˆ—è¡¨åŠŸèƒ½
    """
    try:
        if not os.path.exists(directory_path):
            return f"é”™è¯¯ï¼šç›®å½• '{directory_path}' ä¸å­˜åœ¨"
        
        if not os.path.isdir(directory_path):
            return f"é”™è¯¯ï¼š'{directory_path}' ä¸æ˜¯ä¸€ä¸ªç›®å½•"
        
        contents = []
        for item in os.listdir(directory_path):
            item_path = os.path.join(directory_path, item)
            if os.path.isdir(item_path):
                contents.append(f"ğŸ“ {item}/")
            else:
                size = os.path.getsize(item_path)
                contents.append(f"ğŸ“„ {item} ({size} bytes)")
        
        if not contents:
            return f"ç›®å½• '{directory_path}' ä¸ºç©º"
        
        return f"ç›®å½• '{directory_path}' å†…å®¹ï¼š\n" + "\n".join(contents)
    
    except PermissionError:
        return f"é”™è¯¯ï¼šæ²¡æœ‰æƒé™è®¿é—®ç›®å½• '{directory_path}'"
    except Exception as e:
        return f"æŸ¥è¯¢ç›®å½•æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}"

@tool(args_schema=FastqQueryArgs)
def query_fastq_files(directory_path: str, pattern: str = "*.fastq*") -> str:
    """
    æŸ¥è¯¢æŒ‡å®šç›®å½•ä¸‹çš„FASTQæ–‡ä»¶ä¿¡æ¯
    
    éµå¾ªDRYåŸåˆ™ï¼šç»Ÿä¸€çš„FASTQæ–‡ä»¶æŸ¥è¯¢é€»è¾‘
    """
    try:
        if not os.path.exists(directory_path):
            return f"é”™è¯¯ï¼šç›®å½• '{directory_path}' ä¸å­˜åœ¨"
        
        # ä½¿ç”¨globæŸ¥æ‰¾FASTQæ–‡ä»¶
        search_pattern = os.path.join(directory_path, "**", pattern)
        fastq_files = glob.glob(search_pattern, recursive=True)
        
        if not fastq_files:
            return f"åœ¨ç›®å½• '{directory_path}' ä¸­æœªæ‰¾åˆ°åŒ¹é… '{pattern}' çš„FASTQæ–‡ä»¶"
        
        # åˆ†ææ–‡ä»¶ä¿¡æ¯
        paired_files = {}
        single_files = []
        
        for file_path in sorted(fastq_files):
            file_name = os.path.basename(file_path)
            file_size = os.path.getsize(file_path)
            
            # åˆ¤æ–­æ˜¯å¦ä¸ºåŒç«¯æµ‹åºæ–‡ä»¶
            if "_1.fastq" in file_name or "_R1" in file_name:
                sample_id = file_name.replace("_1.fastq", "").replace("_R1", "").split(".")[0]
                if sample_id not in paired_files:
                    paired_files[sample_id] = {}
                paired_files[sample_id]["R1"] = {"path": file_path, "size": file_size}
            elif "_2.fastq" in file_name or "_R2" in file_name:
                sample_id = file_name.replace("_2.fastq", "").replace("_R2", "").split(".")[0]
                if sample_id not in paired_files:
                    paired_files[sample_id] = {}
                paired_files[sample_id]["R2"] = {"path": file_path, "size": file_size}
            else:
                single_files.append({"name": file_name, "path": file_path, "size": file_size})
        
        # æ„å»ºç»“æœ
        result = [f"FASTQæ–‡ä»¶æŸ¥è¯¢ç»“æœ (ç›®å½•: {directory_path})ï¼š\n"]
        
        if paired_files:
            result.append("åŒç«¯æµ‹åºæ–‡ä»¶ï¼š")
            for sample_id, files in paired_files.items():
                result.append(f"  æ ·æœ¬: {sample_id}")
                if "R1" in files:
                    result.append(f"    R1: {files['R1']['path']} ({files['R1']['size']} bytes)")
                if "R2" in files:
                    result.append(f"    R2: {files['R2']['path']} ({files['R2']['size']} bytes)")
        
        if single_files:
            result.append("\nå•ç«¯æµ‹åºæ–‡ä»¶ï¼š")
            for file_info in single_files:
                result.append(f"  {file_info['name']}: {file_info['path']} ({file_info['size']} bytes)")
        
        result.append(f"\næ€»è®¡ï¼š{len(paired_files)} ä¸ªåŒç«¯æ ·æœ¬ï¼Œ{len(single_files)} ä¸ªå•ç«¯æ–‡ä»¶")
        
        return "\n".join(result)
    
    except Exception as e:
        return f"æŸ¥è¯¢FASTQæ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}"

@tool(args_schema=GenomeQueryArgs)
def query_genome_info(genome_name: Optional[str] = None, config_path: str = "config/genomes.json") -> str:
    """
    æŸ¥è¯¢åŸºå› ç»„é…ç½®ä¿¡æ¯
    
    éµå¾ªå•ä¸€èŒè´£åŸåˆ™ï¼šä¸“é—¨å¤„ç†åŸºå› ç»„ä¿¡æ¯æŸ¥è¯¢
    å½“ä¸æä¾›genome_nameæ—¶ï¼Œè¿”å›æ‰€æœ‰åŸºå› ç»„çš„æ‘˜è¦ä¿¡æ¯
    å½“æä¾›genome_nameæ—¶ï¼Œè¿”å›ç‰¹å®šåŸºå› ç»„çš„è¯¦ç»†ä¿¡æ¯
    """
    try:
        if not os.path.exists(config_path):
            return f"é”™è¯¯ï¼šåŸºå› ç»„é…ç½®æ–‡ä»¶ '{config_path}' ä¸å­˜åœ¨"
        
        with open(config_path, 'r', encoding='utf-8') as f:
            genomes_config = json.load(f)
        
        # å¦‚æœæ²¡æœ‰æä¾›genome_nameï¼Œè¿”å›æ‰€æœ‰åŸºå› ç»„çš„æ‘˜è¦ä¿¡æ¯
        if genome_name is None:
            result = ["å¯ç”¨åŸºå› ç»„æ‘˜è¦ä¿¡æ¯ï¼š"]
            result.append("-" * 60)
            
            for name, info in genomes_config.items():
                result.append(f"åŸºå› ç»„: {name}")
                result.append(f"  ç‰©ç§: {info.get('species', 'æœªçŸ¥')}")
                result.append(f"  ç‰ˆæœ¬: {info.get('version', 'æœªçŸ¥')}")
                
                # æ£€æŸ¥æœ¬åœ°æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                fasta_path = info.get('fasta', '')
                gtf_path = info.get('gtf', '')
                
                fasta_status = "âœ… å·²å­˜åœ¨" if fasta_path and os.path.exists(fasta_path) else "âŒ ä¸å­˜åœ¨"
                gtf_status = "âœ… å·²å­˜åœ¨" if gtf_path and os.path.exists(gtf_path) else "âŒ ä¸å­˜åœ¨"
                
                result.append(f"  FASTAæ–‡ä»¶: {fasta_status}")
                result.append(f"  GTFæ–‡ä»¶: {gtf_status}")
                result.append("-" * 60)
            
            result.append(f"æ€»è®¡ï¼š{len(genomes_config)} ä¸ªåŸºå› ç»„å¯ç”¨")
            return "\n".join(result)
        
        # å¦‚æœæä¾›äº†genome_nameï¼Œè¿”å›ç‰¹å®šåŸºå› ç»„çš„è¯¦ç»†ä¿¡æ¯
        if genome_name not in genomes_config:
            available_genomes = list(genomes_config.keys())
            return f"é”™è¯¯ï¼šåŸºå› ç»„ '{genome_name}' ä¸å­˜åœ¨ã€‚å¯ç”¨åŸºå› ç»„ï¼š{', '.join(available_genomes)}"
        
        genome_info = genomes_config[genome_name]
        
        result = [f"åŸºå› ç»„ '{genome_name}' è¯¦ç»†ä¿¡æ¯ï¼š"]
        result.append(f"  ç‰©ç§: {genome_info.get('species', 'æœªçŸ¥')}")
        result.append(f"  ç‰ˆæœ¬: {genome_info.get('version', 'æœªçŸ¥')}")
        result.append(f"  FASTAæ–‡ä»¶: {genome_info.get('fasta', 'æœªé…ç½®')}")
        result.append(f"  GTFæ–‡ä»¶: {genome_info.get('gtf', 'æœªé…ç½®')}")
        
        if 'fasta_url' in genome_info:
            result.append(f"  FASTAä¸‹è½½URL: {genome_info['fasta_url']}")
        if 'gtf_url' in genome_info:
            result.append(f"  GTFä¸‹è½½URL: {genome_info['gtf_url']}")
        
        # æ£€æŸ¥æœ¬åœ°æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        fasta_path = genome_info.get('fasta', '')
        gtf_path = genome_info.get('gtf', '')
        
        if fasta_path and os.path.exists(fasta_path):
            result.append(f"  âœ… FASTAæ–‡ä»¶å·²å­˜åœ¨")
        elif fasta_path:
            result.append(f"  âŒ FASTAæ–‡ä»¶ä¸å­˜åœ¨")
        
        if gtf_path and os.path.exists(gtf_path):
            result.append(f"  âœ… GTFæ–‡ä»¶å·²å­˜åœ¨")
        elif gtf_path:
            result.append(f"  âŒ GTFæ–‡ä»¶ä¸å­˜åœ¨")
        
        return "\n".join(result)
    
    except json.JSONDecodeError:
        return f"é”™è¯¯ï¼šåŸºå› ç»„é…ç½®æ–‡ä»¶ '{config_path}' æ ¼å¼ä¸æ­£ç¡®"
    except Exception as e:
        return f"æŸ¥è¯¢åŸºå› ç»„ä¿¡æ¯æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}"

# ============================================================================
# é…ç½®ç®¡ç†å·¥å…·ç»„ - éµå¾ªDRYåŸåˆ™
# ============================================================================

@tool(args_schema=NextflowConfigArgs)
def update_nextflow_param(param_name: str, param_value: Any) -> str:
    """
    æ›´æ–°å•ä¸ªnextflowå‚æ•°
    
    åº”ç”¨KISSåŸåˆ™ï¼šç®€å•çš„å•å‚æ•°æ›´æ–°
    """
    try:
        # éªŒè¯å‚æ•°åç§°
        valid_params = [
            "srr_ids", "local_genome_path", "local_gtf_path", 
            "download_genome_url", "download_gtf_url", "local_fastq_files",
            "data", "run_download_srr", "run_download_genome", 
            "run_build_star_index", "run_fastp", "run_star_align", "run_featurecounts"
        ]
        
        if param_name not in valid_params:
            return f"é”™è¯¯ï¼šæ— æ•ˆçš„å‚æ•°å '{param_name}'ã€‚æœ‰æ•ˆå‚æ•°ï¼š{', '.join(valid_params)}"
        
        # ç±»å‹éªŒè¯
        if param_name.startswith("run_") and not isinstance(param_value, bool):
            return f"é”™è¯¯ï¼šå‚æ•° '{param_name}' å¿…é¡»æ˜¯å¸ƒå°”å€¼"
        
        return f"âœ… å‚æ•° '{param_name}' å·²æ›´æ–°ä¸º: {param_value}"
    
    except Exception as e:
        return f"æ›´æ–°å‚æ•°æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}"

@tool(args_schema=BatchConfigArgs)
def batch_update_nextflow_config(config_updates: Dict[str, Any]) -> str:
    """
    æ‰¹é‡æ›´æ–°nextflowé…ç½®
    
    éµå¾ªDRYåŸåˆ™ï¼šå¤ç”¨å•å‚æ•°æ›´æ–°é€»è¾‘
    """
    try:
        results = []
        for param_name, param_value in config_updates.items():
            result = update_nextflow_param(param_name, param_value)
            results.append(result)
        
        success_count = sum(1 for r in results if r.startswith("âœ…"))
        error_count = len(results) - success_count
        
        summary = f"æ‰¹é‡æ›´æ–°å®Œæˆï¼š{success_count} ä¸ªæˆåŠŸï¼Œ{error_count} ä¸ªå¤±è´¥"
        return summary + "\n\n" + "\n".join(results)
    
    except Exception as e:
        return f"æ‰¹é‡æ›´æ–°é…ç½®æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}"

# ============================================================================
# æ¨¡å¼æ§åˆ¶å·¥å…·ç»„ - éµå¾ªå¼€æ”¾å°é—­åŸåˆ™
# ============================================================================

@tool(args_schema=ModeSwitch)
def switch_to_plan_mode(target_mode: str, reason: str) -> str:
    """
    åˆ‡æ¢åˆ°è®¡åˆ’æ¨¡å¼
    
    éµå¾ªå•ä¸€èŒè´£åŸåˆ™ï¼šä¸“é—¨å¤„ç†æ¨¡å¼åˆ‡æ¢
    """
    if target_mode != "plan":
        return f"é”™è¯¯ï¼šæ­¤å·¥å…·åªèƒ½åˆ‡æ¢åˆ°planæ¨¡å¼ï¼Œæ”¶åˆ°ï¼š{target_mode}"
    
    return f"ğŸ”„ æ­£åœ¨åˆ‡æ¢åˆ°è®¡åˆ’æ¨¡å¼...\nåŸå› ï¼š{reason}\nâœ… æ¨¡å¼åˆ‡æ¢æˆåŠŸï¼ç°åœ¨å¯ä»¥å¼€å§‹åˆ¶å®šRNA-seqåˆ†æè®¡åˆ’ã€‚"

@tool(args_schema=ModeSwitch)
def switch_to_execute_mode(target_mode: str, reason: str) -> str:
    """
    åˆ‡æ¢åˆ°æ‰§è¡Œæ¨¡å¼
    
    éµå¾ªå•ä¸€èŒè´£åŸåˆ™ï¼šä¸“é—¨å¤„ç†æ¨¡å¼åˆ‡æ¢
    """
    if target_mode != "execute":
        return f"é”™è¯¯ï¼šæ­¤å·¥å…·åªèƒ½åˆ‡æ¢åˆ°executeæ¨¡å¼ï¼Œæ”¶åˆ°ï¼š{target_mode}"
    
    return f"ğŸ”„ æ­£åœ¨åˆ‡æ¢åˆ°æ‰§è¡Œæ¨¡å¼...\nåŸå› ï¼š{reason}\nâœ… æ¨¡å¼åˆ‡æ¢æˆåŠŸï¼å‡†å¤‡æ‰§è¡Œnextflowæµç¨‹ã€‚"

# ============================================================================
# æ‰§è¡Œæ§åˆ¶å·¥å…·ç»„ - éµå¾ªå•ä¸€èŒè´£åŸåˆ™
# ============================================================================

@tool(args_schema=ExecutionArgs)
def execute_nextflow_pipeline(config_path: str = "config/nextflow.config", work_dir: str = "./work") -> str:
    """
    æ‰§è¡Œnextflowæµç¨‹
    
    åº”ç”¨KISSåŸåˆ™ï¼šç®€å•çš„æµç¨‹æ‰§è¡Œ
    """
    try:
        # æ£€æŸ¥nextflowæ˜¯å¦å¯ç”¨
        result = subprocess.run(["nextflow", "-version"], capture_output=True, text=True)
        if result.returncode != 0:
            return "é”™è¯¯ï¼šnextflowæœªå®‰è£…æˆ–ä¸å¯ç”¨"
        
        # æ„å»ºæ‰§è¡Œå‘½ä»¤
        cmd = [
            "nextflow", "run", "main.nf",
            "-c", config_path,
            "-work-dir", work_dir
        ]
        
        return f"ğŸš€ å¼€å§‹æ‰§è¡Œnextflowæµç¨‹...\nå‘½ä»¤ï¼š{' '.join(cmd)}\nâ³ æµç¨‹æ­£åœ¨åå°è¿è¡Œï¼Œè¯·ä½¿ç”¨check_execution_statusæŸ¥çœ‹çŠ¶æ€ã€‚"
    
    except Exception as e:
        return f"æ‰§è¡Œnextflowæµç¨‹æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}"

@tool
def check_execution_status() -> str:
    """
    æ£€æŸ¥æ‰§è¡ŒçŠ¶æ€
    
    åº”ç”¨KISSåŸåˆ™ï¼šç®€å•çš„çŠ¶æ€æ£€æŸ¥
    """
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰nextflowè¿›ç¨‹åœ¨è¿è¡Œ
        result = subprocess.run(["pgrep", "-f", "nextflow"], capture_output=True, text=True)
        
        if result.returncode == 0:
            return "âœ… Nextflowæµç¨‹æ­£åœ¨è¿è¡Œä¸­..."
        else:
            return "â¹ï¸ æ²¡æœ‰æ£€æµ‹åˆ°æ­£åœ¨è¿è¡Œçš„nextflowæµç¨‹"
    
    except Exception as e:
        return f"æ£€æŸ¥æ‰§è¡ŒçŠ¶æ€æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}"

@tool
def get_current_nextflow_config() -> str:
    """
    è·å–å½“å‰nextflowé…ç½®çŠ¶æ€
    
    éµå¾ªå•ä¸€èŒè´£åŸåˆ™ï¼šä¸“é—¨è·å–é…ç½®ä¿¡æ¯
    """
    try:
        # è¿™é‡Œåº”è¯¥ä»çŠ¶æ€ç®¡ç†ä¸­è·å–é…ç½®ï¼Œæš‚æ—¶è¿”å›é»˜è®¤é…ç½®
        default_config = {
            "srr_ids": "",
            "local_genome_path": "",
            "local_gtf_path": "",
            "download_genome_url": "",
            "download_gtf_url": "",
            "local_fastq_files": "",
            "data": "./data",
            "run_download_srr": False,
            "run_download_genome": False,
            "run_build_star_index": False,
            "run_fastp": False,
            "run_star_align": False,
            "run_featurecounts": False
        }
        
        result = ["å½“å‰nextflowé…ç½®ï¼š"]
        for key, value in default_config.items():
            result.append(f"  {key}: {value}")
        
        return "\n".join(result)
    
    except Exception as e:
        return f"è·å–é…ç½®æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}"

# ============================================================================
# ç›®å½•æ ‘å·¥å…·ç»„ - éµå¾ªå•ä¸€èŒè´£åŸåˆ™
# ============================================================================

def _generate_simple_list(directory_path: str, max_depth: Optional[int] = None,
                         file_pattern: Optional[str] = None, show_only_files: bool = False) -> str:
    """
    ç”Ÿæˆç®€å•åˆ—è¡¨æ ¼å¼çš„ç›®å½•å†…å®¹
    
    éµå¾ªå•ä¸€èŒè´£åŸåˆ™ï¼šä¸“é—¨å¤„ç†ç®€å•åˆ—è¡¨æ ¼å¼è¾“å‡º
    """
    try:
        path = Path(directory_path)
        if not path.exists():
            return f"é”™è¯¯ï¼šç›®å½• '{directory_path}' ä¸å­˜åœ¨"
        
        if not path.is_dir():
            return f"é”™è¯¯ï¼š'{directory_path}' ä¸æ˜¯ä¸€ä¸ªç›®å½•"
        
        contents = []
        
        # æ ¹æ®æœ€å¤§æ·±åº¦å†³å®šä½¿ç”¨rglobè¿˜æ˜¯glob
        if max_depth is None or max_depth > 1:
            # ä½¿ç”¨rglobè¿›è¡Œé€’å½’æŸ¥æ‰¾
            pattern = file_pattern if file_pattern else "*"
            for item in path.rglob(pattern):
                if max_depth is not None:
                    # è®¡ç®—ç›¸å¯¹æ·±åº¦
                    relative_path = item.relative_to(path)
                    depth = len(relative_path.parts) - 1
                    if depth > max_depth:
                        continue
                
                if show_only_files and item.is_dir():
                    continue
                
                if item.is_dir():
                    contents.append(f"ğŸ“ {item}/")
                else:
                    size = item.stat().st_size
                    contents.append(f"ğŸ“„ {item} ({size} bytes)")
        else:
            # åªæŸ¥æ‰¾å½“å‰ç›®å½•
            pattern = file_pattern if file_pattern else "*"
            for item in path.glob(pattern):
                if show_only_files and item.is_dir():
                    continue
                
                if item.is_dir():
                    contents.append(f"ğŸ“ {item}/")
                else:
                    size = item.stat().st_size
                    contents.append(f"ğŸ“„ {item} ({size} bytes)")
        
        if not contents:
            return f"ç›®å½• '{directory_path}' ä¸­æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„å†…å®¹"
        
        return f"ç›®å½• '{directory_path}' å†…å®¹åˆ—è¡¨ï¼š\n" + "\n".join(contents)
    
    except Exception as e:
        return f"ç”Ÿæˆç®€å•åˆ—è¡¨æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}"

def _generate_tree_structure(directory_path: str, max_depth: Optional[int] = None,
                           file_pattern: Optional[str] = None, show_only_files: bool = False,
                           prefix: str = "", current_depth: int = 0) -> str:
    """
    ç”Ÿæˆæ ‘å½¢ç»“æ„çš„ç›®å½•å†…å®¹
    
    éµå¾ªé€’å½’è®¾è®¡æ¨¡å¼ï¼šä½¿ç”¨é€’å½’æ„å»ºæ ‘å½¢ç»“æ„
    """
    try:
        path = Path(directory_path)
        if not path.exists():
            return f"é”™è¯¯ï¼šç›®å½• '{directory_path}' ä¸å­˜åœ¨"
        
        if not path.is_dir():
            return f"é”™è¯¯ï¼š'{directory_path}' ä¸æ˜¯ä¸€ä¸ªç›®å½•"
        
        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡æœ€å¤§æ·±åº¦
        if max_depth is not None and current_depth > max_depth:
            return ""
        
        result = []
        
        try:
            items = sorted(path.iterdir(), key=lambda x: (x.is_file(), x.name.lower()))
        except PermissionError:
            return f"{prefix}âŒ æ²¡æœ‰æƒé™è®¿é—®æ­¤ç›®å½•"
        
        # è¿‡æ»¤æ–‡ä»¶
        if file_pattern:
            import fnmatch
            items = [item for item in items if item.is_dir() or fnmatch.fnmatch(item.name, file_pattern)]
        
        for i, item in enumerate(items):
            is_last = i == len(items) - 1
            
            # è·³è¿‡ç›®å½•ï¼ˆå¦‚æœåªæ˜¾ç¤ºæ–‡ä»¶ï¼‰
            if show_only_files and item.is_dir():
                continue
            
            # æ·»åŠ å½“å‰é¡¹
            if item.is_dir():
                connector = "â””â”€â”€ " if is_last else "â”œâ”€â”€ "
                result.append(f"{prefix}{connector}ğŸ“ {item.name}/")
                
                # é€’å½’å¤„ç†å­ç›®å½•
                if max_depth is None or current_depth < max_depth:
                    extension = "    " if is_last else "â”‚   "
                    subtree = _generate_tree_structure(
                        str(item), max_depth, file_pattern, show_only_files,
                        prefix + extension, current_depth + 1
                    )
                    if subtree:
                        result.append(subtree)
            else:
                connector = "â””â”€â”€ " if is_last else "â”œâ”€â”€ "
                size = item.stat().st_size
                result.append(f"{prefix}{connector}ğŸ“„ {item.name} ({size} bytes)")
        
        return "\n".join(result)
    
    except Exception as e:
        return f"ç”Ÿæˆæ ‘å½¢ç»“æ„æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}"

@tool(args_schema=TreeListArgs)
def list_directory_tree(directory_path: str, max_depth: Optional[int] = None,
                       file_pattern: Optional[str] = None, show_only_files: bool = False,
                       output_format: str = "tree") -> str:
    """
    åˆ—å‡ºç›®å½•æ ‘ç»“æ„æˆ–ç®€å•åˆ—è¡¨
    
    éµå¾ªå•ä¸€èŒè´£åŸåˆ™ï¼šä¸“é—¨å¤„ç†ç›®å½•æ ‘å’Œåˆ—è¡¨æ˜¾ç¤º
    æä¾›å¤šç§è¾“å‡ºæ ¼å¼å’Œè¿‡æ»¤é€‰é¡¹
    """
    try:
        # éªŒè¯è¾“å‡ºæ ¼å¼
        if output_format not in ["tree", "list"]:
            return f"é”™è¯¯ï¼šä¸æ”¯æŒçš„è¾“å‡ºæ ¼å¼ '{output_format}'ã€‚æ”¯æŒçš„æ ¼å¼ï¼š'tree', 'list'"
        
        # æ ¹æ®è¾“å‡ºæ ¼å¼è°ƒç”¨ç›¸åº”çš„è¾…åŠ©å‡½æ•°
        if output_format == "tree":
            result = _generate_tree_structure(directory_path, max_depth, file_pattern, show_only_files)
            if not result.startswith("é”™è¯¯ï¼š"):
                result = f"ç›®å½• '{directory_path}' æ ‘å½¢ç»“æ„ï¼š\n{result}"
            return result
        else:  # output_format == "list"
            return _generate_simple_list(directory_path, max_depth, file_pattern, show_only_files)
    
    except Exception as e:
        return f"åˆ—å‡ºç›®å½•æ ‘æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}"