#!/usr/bin/env python3
"""
RNA-seqæ™ºèƒ½åˆ†æåŠ©æ‰‹ - ä¸»ç¨‹åºå…¥å£
åŸºäºLangGraph Plan-and-Executeæ¶æ„çš„AI Agentç³»ç»Ÿ

é‡æ„ç‰ˆæœ¬ - æ¸…ç†äº†å¯¼å…¥è·¯å¾„ï¼Œä½¿ç”¨æ–°çš„é…ç½®ç®¡ç†ç³»ç»Ÿ
"""

import sys
import asyncio
from pathlib import Path
 

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„ - ä¿®å¤å¯¼å…¥é—®é¢˜
PROJECT_ROOT = Path(__file__).parent
sys.path.insert(0, str(PROJECT_ROOT))

# ç°åœ¨ä½¿ç”¨æ­£ç¡®çš„å¯¼å…¥è·¯å¾„
from src.config.settings import Settings
from src.state import AgentState
from src.graph import create_agent
from src.core import test_llm_connection
 

# æ—¥å¿—åˆå§‹åŒ–
try:
    from src.logging_bootstrap import setup_logging, log_startup_info
    setup_logging()
    log_startup_info()
except Exception as e:
    print(f"âš ï¸ æ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
    pass

def initialize_application() -> Settings:
    """åˆå§‹åŒ–åº”ç”¨ç¨‹åºé…ç½®"""
    print("ğŸš€ åˆå§‹åŒ–RNA-seqæ™ºèƒ½åˆ†æåŠ©æ‰‹...")
    
    # åˆ›å»ºé…ç½®å®ä¾‹
    settings = Settings()
    
    # éªŒè¯ç¯å¢ƒé…ç½®
    is_valid, errors = settings.validate_environment()
    
    if not is_valid:
        print("âŒ ç¯å¢ƒé…ç½®éªŒè¯å¤±è´¥:")
        for error in errors:
            print(f"   - {error}")
        sys.exit(1)
    
    # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
    print(f"âœ… ç¯å¢ƒç±»å‹: å®¹å™¨ç¯å¢ƒ")
    print(f"âœ… æ•°æ®ç›®å½•: {settings.data_dir}")
    
    # éªŒè¯å…³é”®æ–‡ä»¶
    if settings.genomes_config_path.exists():
        print(f"âœ… åŸºå› ç»„é…ç½®æ–‡ä»¶å­˜åœ¨: {settings.genomes_config_path}")
    else:
        print(f"âš ï¸ åŸºå› ç»„é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {settings.genomes_config_path}")
    
    return settings

def validate_llm_connection() -> bool:
    """éªŒè¯LLMè¿æ¥"""
    print("ğŸ”— éªŒè¯DeepSeek LLMè¿æ¥...")
    
    success, message = test_llm_connection()
    
    if success:
        print(f"âœ… DeepSeek LLMè¿æ¥æˆåŠŸ: {message}")
        return True
    else:
        print(f"âŒ DeepSeek LLMè¿æ¥å¤±è´¥: {message}")
        return False

async def run_interactive_session(agent, settings: Settings):
    """è¿è¡Œäº¤äº’å¼ä¼šè¯"""
    # å¯åŠ¨æç¤ºç²¾ç®€ï¼šç§»é™¤å†—é•¿çš„äº¤äº’æç¤º
    
    # åˆ›å»ºåˆå§‹çŠ¶æ€
    initial_state = AgentState(status="normal")
    
    try:
        # ä½¿ç”¨æµå¼è°ƒç”¨å¤„ç†ç”¨æˆ·äº¤äº’
        async for chunk in agent.astream(initial_state):
            # å¤„ç†èŠ‚ç‚¹æ›´æ–°
            for node_name, node_update in chunk.items():
                if node_update and isinstance(node_update, dict):
                    # æ˜¾ç¤ºå“åº”ä¿¡æ¯
                    response = node_update.get("response", "")
                    if response:
                        print(f"ğŸ”„ [{node_name}]: {response}")
                    
                    # æ˜¾ç¤ºçŠ¶æ€æ›´æ–°
                    status = node_update.get("status", "")
                    if status and status != "normal":
                        print(f"ğŸ“Š çŠ¶æ€æ›´æ–°: {status}")
        
        # ç»“æŸæç¤ºç²¾ç®€
        
    except KeyboardInterrupt:
        print("\nğŸ‘‹ æ­£åœ¨å®‰å…¨é€€å‡º...")
    except Exception as e:
        print(f"âŒ è¿è¡Œæ—¶é”™è¯¯: {e}")
        if settings.debug_mode:
            import traceback
            traceback.print_exc()

async def main():
    """ä¸»å‡½æ•° - åº”ç”¨ç¨‹åºå…¥å£ç‚¹"""
    try:
        # 1. åˆå§‹åŒ–é…ç½®
        settings = initialize_application()
        
        # 2. éªŒè¯LLMè¿æ¥  
        if not validate_llm_connection():
            sys.exit(1)
        
        # 3. åˆ›å»ºAgent
        print("âš™ï¸ åˆ›å»ºLangGraph Agent...")
        agent = create_agent()
        print("âœ… Agentåˆ›å»ºæˆåŠŸ")
        
        # 4. è¿è¡Œäº¤äº’å¼ä¼šè¯
        await run_interactive_session(agent, settings)
        
    except Exception as e:
        print(f"âŒ å¯åŠ¨å¤±è´¥: {e}")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())
