"""
FeatureCountsèŠ‚ç‚¹ - ç”¨äºæ‰§è¡ŒåŸºå› å®šé‡åˆ†æ
"""

from typing import Any, Dict
from langgraph.prebuilt import create_react_agent
from ..state import AgentState, FeaturecountsResponse
from ..core import get_shared_llm
from ..prompts import FEATURECOUNTS_OPTIMIZATION_PROMPT
from ..tools import (
    run_nextflow_featurecounts,
    parse_featurecounts_metrics,
    scan_genome_files,
    extract_genome_paths
)
from ..route_decider import decide_next_action_featurecounts
from ..logging_bootstrap import get_logger, log_llm_preview
import json
from datetime import datetime


def create_featurecounts_agent():
    """åˆ›å»ºFeatureCountsèŠ‚ç‚¹çš„React Agent"""
    llm = get_shared_llm()
    
    # ç»‘å®šFeatureCountsç›¸å…³å·¥å…·
    tools = [
        scan_genome_files,
        run_nextflow_featurecounts, 
        parse_featurecounts_metrics
    ]
    
    # åˆ›å»ºReact Agentï¼Œä½¿ç”¨ä¸“ä¸šçš„FeatureCountsä¼˜åŒ–Prompt
    agent = create_react_agent(
        model=llm,
        tools=tools,
        prompt=FEATURECOUNTS_OPTIMIZATION_PROMPT,
        response_format=FeaturecountsResponse
    )
    return agent

def append_featurecounts_optimization_history(state: AgentState, optimization_params: Dict[str, Any], 
                                           suggestions: str, results: Dict[str, Any]) -> None:
    """è¿½åŠ FeatureCountsä¼˜åŒ–å†å²è®°å½•ï¼Œä¿æŒæœ€è¿‘5æ¬¡è®°å½•"""
    history_entry = {
        "timestamp": datetime.now().isoformat(),
        "execution_id": f"featurecounts_run_{len(state.featurecounts_optimization_history) + 1}",
        "optimization_params": optimization_params or {},
        "optimization_suggestions": suggestions or "",
        "execution_results": results or {}
    }
    
    # è¿½åŠ æ–°è®°å½•
    state.featurecounts_optimization_history.append(history_entry)
    
    # ä¿æŒæœ€è¿‘5æ¬¡è®°å½•
    if len(state.featurecounts_optimization_history) > 5:
        state.featurecounts_optimization_history = state.featurecounts_optimization_history[-5:]
    
    logger = get_logger("rna.nodes.featurecounts")
    logger.info(f"[FEATURECOUNTS] å·²è¿½åŠ ä¼˜åŒ–å†å²è®°å½•ï¼Œå½“å‰ä¿å­˜{len(state.featurecounts_optimization_history)}æ¬¡å†å²")


async def featurecounts_node(state: AgentState) -> Dict[str, Any]:
    """
    FeatureCountsèŠ‚ç‚¹å®ç° - æ‰§è¡ŒåŸºå› å®šé‡å¹¶ç”Ÿæˆä¼˜åŒ–å»ºè®®
    
    åŠŸèƒ½ï¼š
    - æ‰§è¡ŒåŸºå› å®šé‡
    - ç”Ÿæˆè¡¨è¾¾çŸ©é˜µ  
    - æ›´æ–°çŠ¶æ€ä¿¡æ¯
    - ç”Ÿæˆoptimization_paramsä¾›è·¯ç”±å†³ç­–å™¨ä½¿ç”¨
    """
    logger = get_logger("rna.nodes.featurecounts")
    logger.info("FeatureCountså®šé‡èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œ")
    
    # æ›´æ–°æ‰§è¡Œè¿›åº¦
    completed_steps = state.completed_steps.copy() if state.completed_steps else []
    if "featurecounts" not in completed_steps:
        completed_steps.append("featurecounts")
    
    # å…è®¸åŸºäº STAR æˆ– HISAT2 çš„æ¯”å¯¹ç»“æœè¿›è¡Œå®šé‡
    has_star = bool(getattr(state, 'star_results', {}) or {}) and bool(state.star_results.get("success"))
    has_hisat2 = bool(getattr(state, 'hisat2_results', {}) or {}) and bool(state.hisat2_results.get("success"))
    if not (has_star or has_hisat2):
        # ä¾èµ–å¤±è´¥æ—¶è®¾ç½®è¿”å›ä¸Šä¸‹æ–‡
        state.return_source = "featurecounts"
        state.return_reason = "failed"

        return {
            "success": False,
            "status": "featurecounts_failed",
            "response": "âŒ FeatureCountsæ‰§è¡Œå¤±è´¥ï¼šç¼ºå°‘æœ‰æ•ˆçš„æ¯”å¯¹ç»“æœï¼ˆSTAR/HISAT2ï¼‰ï¼Œè¯·å…ˆå®Œæˆæ¯”å¯¹",
            "current_step": "featurecounts",
            "completed_steps": completed_steps,
            "featurecounts_results": {
                "success": False,
                "status": "failed",
                "error": "æ¯”å¯¹ç»“æœä¸å¯ç”¨æˆ–æœªæˆåŠŸ"
            }
        }
    
    try:
        logger.info("[FEATURECOUNTS] ä½¿ç”¨FeatureCounts Agentè¿›è¡Œå®šé‡åˆ†æå’Œä¼˜åŒ–...")
        
        # ç»Ÿä¸€è°ƒç”¨FeatureCounts Agentæ‰§è¡Œå®šé‡å’Œä¼˜åŒ–åˆ†æ
        fc_response = await _call_featurecounts_optimization_agent(state)
        
        # ç«‹å³æ›´æ–°æ‰§è¡Œå‚æ•°å’Œä¼˜åŒ–å»ºè®®
        optimized_params = fc_response.featurecounts_params
        optimization_reasoning = fc_response.featurecounts_optimization_suggestions
        optimization_params_changes = fc_response.featurecounts_optimization_params
        
        # é€ä¼ Agentè¿”å›çš„results
        agent_results = getattr(fc_response, 'featurecounts_results', None)
        fc_results = {
            "success": True,
            "status": "success",
        }
        if agent_results and isinstance(agent_results, dict):
            fc_results.update(agent_results)
        
        result = {
            "success": True,
            "status": "featurecounts_completed",
            "current_step": "featurecounts",
            "completed_steps": completed_steps,
            "featurecounts_params": optimized_params,
            "featurecounts_optimization_suggestions": optimization_reasoning,
            "featurecounts_optimization_params": optimization_params_changes,
            "featurecounts_results": fc_results,
        }

        # ç”Ÿæˆå“åº”ä¿¡æ¯
        optimization_count = len(optimization_params_changes or {})
        if optimization_count > 0:
            result["response"] = (
                f"âœ… FeatureCountså®šé‡å®Œæˆ\n- å®šé‡çŠ¶æ€: æˆåŠŸå®Œæˆ\n- ä¼˜åŒ–åˆ†æ: ç”Ÿæˆäº†{optimization_count}ä¸ªä¼˜åŒ–å»ºè®®\n\n"
                f"âš¡ ä¼˜åŒ–è¯¦æƒ…: {optimization_reasoning}"
            )
        else:
            result["response"] = (
                "âœ… FeatureCountså®šé‡å®Œæˆ\n\n"
                "ğŸš€ æ‰§è¡Œè¯¦æƒ…: å·²å®ŒæˆåŸºå› å®šé‡ï¼Œå½“å‰å‚æ•°é…ç½®å·²æ˜¯æœ€ä¼˜"
            )

        # æ ¹æ®è·¯ç”±å†³ç­–å™¨ç»“æœè®¾ç½®è¿”å›ä¸Šä¸‹æ–‡
        next_action = decide_next_action_featurecounts(state)
        if next_action == "return_confirm":
            state.return_source = "featurecounts"
            if not fc_results.get("success", True):
                state.return_reason = "failed"
            elif state.execution_mode == 'batch_optimize':
                state.return_reason = "batch_collect"  # Batchæ¨¡å¼ç‰¹æ®Šå¤„ç†
            else:
                state.return_reason = "step_confirm"

        # è¿½åŠ ä¼˜åŒ–å†å²è®°å½•
        append_featurecounts_optimization_history(
            state=state,
            optimization_params=optimization_params_changes,
            suggestions=optimization_reasoning,
            results=fc_results
        )

        logger.info(f"[FEATURECOUNTS] FeatureCountsæ‰§è¡Œå®Œæˆï¼Œç”Ÿæˆ{optimization_count}ä¸ªä¼˜åŒ–å‚æ•°")
        return result
            
    except Exception as e:
        logger.error(f"FeatureCountsèŠ‚ç‚¹æ‰§è¡Œå¤±è´¥: {str(e)}", exc_info=True)

        # å¤±è´¥æ—¶è®¾ç½®è¿”å›ä¸Šä¸‹æ–‡
        state.return_source = "featurecounts"
        state.return_reason = "failed"

        return {
            "success": False,
            "status": "featurecounts_failed",
            "response": f"âŒ FeatureCountså®šé‡æ‰§è¡Œå¤±è´¥: {str(e)}",
            "current_step": "featurecounts",
            "completed_steps": completed_steps,
            "featurecounts_results": {
                "success": False,
                "status": "failed",
                "error": str(e)
            },
        }


async def _call_featurecounts_optimization_agent(state: AgentState) -> FeaturecountsResponse:
    """è°ƒç”¨FeatureCountsä¼˜åŒ–Agentè¿›è¡Œæ™ºèƒ½å‚æ•°ä¼˜åŒ–"""
    
    logger = get_logger("rna.nodes.featurecounts")
    
    # è·å–åŸºå› ç»„é…ç½®ä¿¡æ¯ï¼ˆä»detectèŠ‚ç‚¹çš„query_resultsä¸­è·å–ï¼‰
    # åŠ¨æ€æå–åŸºå› ç»„è·¯å¾„ä¿¡æ¯
    genome_paths = extract_genome_paths(state)
    genome_version = state.nextflow_config.get("genome_version")
    
    # æå–GTFè·¯å¾„ç”¨äºå·¥å…·è°ƒç”¨
    gtf_path = genome_paths.get("gtf_path", "")
    
    # æå–èµ„æºé…ç½®ç‰‡æ®µï¼ˆä»… FeatureCountsï¼‰
    featurecounts_resource_config = state.resource_config.get("featurecounts") if state.resource_config else {}

    user_context = {
        "execution_mode": state.execution_mode,
        "genome_config": {
            "genome_version": genome_version,
            "paired_end": state.nextflow_config.get("paired_end")
        },
        "gtf_path": gtf_path,  # ç®€åŒ–ä¼ é€’ï¼Œåªæä¾›GTFè·¯å¾„
        "featurecounts_resource_config": featurecounts_resource_config,
        "current_featurecounts_params": state.featurecounts_params,
        "star_results": getattr(state, 'star_results', {}),
        "hisat2_results": getattr(state, 'hisat2_results', {}),
        "optimization_history": state.featurecounts_optimization_history
    }
    
    user_prompt = json.dumps(user_context, ensure_ascii=False, indent=2)
    
    # åˆ›å»ºå¹¶è°ƒç”¨Agent
    agent_executor = create_featurecounts_agent()
    
    # æ„å»ºæ¶ˆæ¯æ ¼å¼
    messages = [
        {"role": "user", "content": user_prompt}
    ]
    
    result = await agent_executor.ainvoke({"messages": messages})
    
    # æå–ç»“æ„åŒ–å“åº”
    structured_response = result.get("structured_response")
    try:
        if structured_response:
            log_llm_preview(logger, "featurecounts", structured_response)
        else:
            log_llm_preview(logger, "featurecounts.raw", {"keys": list(result.keys())[:10]})
    except Exception:
        pass
    if not structured_response:
        raise ValueError("Agentè¿”å›çš„ç»“æ„åŒ–å“åº”ä¸ºç©º")
    
    return structured_response
