"""
FeatureCountsèŠ‚ç‚¹ - ç”¨äºæ‰§è¡ŒåŸºå› å®šé‡åˆ†æ
"""

from typing import Any, Dict
from langgraph.prebuilt import create_react_agent
from ..state import AgentState, FeaturecountsResponse
from ..core import get_shared_llm
from ..prompts import FEATURECOUNTS_OPTIMIZATION_PROMPT
from ..tools import (
    run_nextflow_featurecounts,
    parse_featurecounts_metrics,
    scan_genome_files
)
from ..logging_bootstrap import get_logger, log_llm_preview
import json
from datetime import datetime


def create_featurecounts_agent():
    """åˆ›å»ºFeatureCountsèŠ‚ç‚¹çš„React Agent"""
    llm = get_shared_llm()
    
    # ç»‘å®šFeatureCountsç›¸å…³å·¥å…·
    tools = [
        scan_genome_files,
        run_nextflow_featurecounts, 
        parse_featurecounts_metrics
    ]
    
    # åˆ›å»ºReact Agentï¼Œä½¿ç”¨ä¸“ä¸šçš„FeatureCountsä¼˜åŒ–Prompt
    agent = create_react_agent(
        model=llm,
        tools=tools,
        prompt=FEATURECOUNTS_OPTIMIZATION_PROMPT,
        response_format=FeaturecountsResponse
    )
    return agent

def append_featurecounts_optimization_history(state: AgentState, optimization_params: Dict[str, Any], 
                                           suggestions: str, results: Dict[str, Any]) -> None:
    """è¿½åŠ FeatureCountsä¼˜åŒ–å†å²è®°å½•ï¼Œä¿æŒæœ€è¿‘5æ¬¡è®°å½•"""
    history_entry = {
        "timestamp": datetime.now().isoformat(),
        "execution_id": f"featurecounts_run_{len(state.featurecounts_optimization_history) + 1}",
        "optimization_params": optimization_params or {},
        "optimization_suggestions": suggestions or "",
        "execution_results": results or {}
    }
    
    # è¿½åŠ æ–°è®°å½•
    state.featurecounts_optimization_history.append(history_entry)
    
    # ä¿æŒæœ€è¿‘5æ¬¡è®°å½•
    if len(state.featurecounts_optimization_history) > 5:
        state.featurecounts_optimization_history = state.featurecounts_optimization_history[-5:]
    
    logger = get_logger("rna.nodes.featurecounts")
    logger.info(f"[FEATURECOUNTS] å·²è¿½åŠ ä¼˜åŒ–å†å²è®°å½•ï¼Œå½“å‰ä¿å­˜{len(state.featurecounts_optimization_history)}æ¬¡å†å²")


async def featurecounts_node(state: AgentState) -> Dict[str, Any]:
    """
    FeatureCountsèŠ‚ç‚¹å®ç° - æ‰§è¡ŒåŸºå› å®šé‡å¹¶ç”Ÿæˆä¼˜åŒ–å»ºè®®
    
    åŠŸèƒ½ï¼š
    - æ‰§è¡ŒåŸºå› å®šé‡
    - ç”Ÿæˆè¡¨è¾¾çŸ©é˜µ  
    - æ›´æ–°çŠ¶æ€ä¿¡æ¯
    - ç”Ÿæˆoptimization_paramsä¾›è·¯ç”±å†³ç­–å™¨ä½¿ç”¨
    """
    logger = get_logger("rna.nodes.featurecounts")
    logger.info("FeatureCountså®šé‡èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œ")
    
    # æ›´æ–°æ‰§è¡Œè¿›åº¦
    completed_steps = state.completed_steps.copy() if state.completed_steps else []
    if "featurecounts" not in completed_steps:
        completed_steps.append("featurecounts")
    
    # å…è®¸åŸºäº STAR æˆ– HISAT2 çš„æ¯”å¯¹ç»“æœè¿›è¡Œå®šé‡
    has_star = bool(getattr(state, 'star_results', {}) or {}) and bool(state.star_results.get("success"))
    has_hisat2 = bool(getattr(state, 'hisat2_results', {}) or {}) and bool(state.hisat2_results.get("success"))
    if not (has_star or has_hisat2):
        return {
            "success": False,
            "status": "featurecounts_failed",
            "response": "âŒ FeatureCountsæ‰§è¡Œå¤±è´¥ï¼šç¼ºå°‘æœ‰æ•ˆçš„æ¯”å¯¹ç»“æœï¼ˆSTAR/HISAT2ï¼‰ï¼Œè¯·å…ˆå®Œæˆæ¯”å¯¹",
            "current_step": "featurecounts",
            "completed_steps": completed_steps,
            "featurecounts_results": {
                "success": False,
                "status": "failed",
                "error": "æ¯”å¯¹ç»“æœä¸å¯ç”¨æˆ–æœªæˆåŠŸ"
            }
        }
    
    try:
        logger.info("[FEATURECOUNTS] ä½¿ç”¨FeatureCounts Agentè¿›è¡Œå®šé‡åˆ†æå’Œä¼˜åŒ–...")
        
        # ç»Ÿä¸€è°ƒç”¨FeatureCounts Agentæ‰§è¡Œå®šé‡å’Œä¼˜åŒ–åˆ†æ
        fc_response = await _call_featurecounts_optimization_agent(state)
        
        # ç«‹å³æ›´æ–°æ‰§è¡Œå‚æ•°å’Œä¼˜åŒ–å»ºè®®
        optimized_params = fc_response.featurecounts_params
        optimization_reasoning = fc_response.featurecounts_optimization_suggestions
        optimization_params_changes = fc_response.featurecounts_optimization_params
        
        # é€ä¼ Agentè¿”å›çš„results
        agent_results = getattr(fc_response, 'results', None)
        fc_results = {
            "success": True,
            "status": "success",
        }
        if agent_results and isinstance(agent_results, dict):
            fc_results.update(agent_results)
        
        result = {
            "success": True,
            "status": "featurecounts_completed",
            "current_step": "featurecounts",
            "completed_steps": completed_steps,
            "featurecounts_params": optimized_params,
            "featurecounts_optimization_suggestions": optimization_reasoning,
            "featurecounts_optimization_params": optimization_params_changes,
            "featurecounts_results": fc_results,
        }

        # ç”Ÿæˆå“åº”ä¿¡æ¯
        optimization_count = len(optimization_params_changes or {})
        if optimization_count > 0:
            result["response"] = (
                f"âœ… FeatureCountså®šé‡å®Œæˆ\n- å®šé‡çŠ¶æ€: æˆåŠŸå®Œæˆ\n- ä¼˜åŒ–åˆ†æ: ç”Ÿæˆäº†{optimization_count}ä¸ªä¼˜åŒ–å»ºè®®\n\n"
                f"âš¡ ä¼˜åŒ–è¯¦æƒ…: {optimization_reasoning}"
            )
        else:
            result["response"] = (
                "âœ… FeatureCountså®šé‡å®Œæˆ\n\n"
                "ğŸš€ æ‰§è¡Œè¯¦æƒ…: å·²å®ŒæˆåŸºå› å®šé‡ï¼Œå½“å‰å‚æ•°é…ç½®å·²æ˜¯æœ€ä¼˜"
            )
        

            
        # è¿½åŠ ä¼˜åŒ–å†å²è®°å½•
        append_featurecounts_optimization_history(
            state=state,
            optimization_params=optimization_params_changes,
            suggestions=optimization_reasoning,
            results=fc_results
        )
        
        logger.info(f"[FEATURECOUNTS] FeatureCountsæ‰§è¡Œå®Œæˆï¼Œç”Ÿæˆ{optimization_count}ä¸ªä¼˜åŒ–å‚æ•°")
        return result
            
    except Exception as e:
        logger.error(f"FeatureCountsèŠ‚ç‚¹æ‰§è¡Œå¤±è´¥: {str(e)}", exc_info=True)
        return {
            "success": False,
            "status": "featurecounts_failed",
            "response": f"âŒ FeatureCountså®šé‡æ‰§è¡Œå¤±è´¥: {str(e)}",
            "current_step": "featurecounts",
            "completed_steps": completed_steps,
            "featurecounts_results": {
                "success": False,
                "status": "failed", 
                "error": str(e)
            },
        }


async def _call_featurecounts_optimization_agent(state: AgentState) -> FeaturecountsResponse:
    """è°ƒç”¨FeatureCountsä¼˜åŒ–Agentè¿›è¡Œæ™ºèƒ½å‚æ•°ä¼˜åŒ–"""
    
    logger = get_logger("rna.nodes.featurecounts")
    
    # ç»„ç»‡æ•°æ®ä¸Šä¸‹æ–‡ï¼ˆä»…æ•°æ®ï¼Œä¸é‡å¤æµç¨‹ä¸æŒ‡å—ï¼Œéµå¾ªç³»ç»Ÿæç¤ºï¼‰
    sample_info = {
        "sample_groups": state.nextflow_config.get("sample_groups", []),
        # ç»“æœç›®å½•å¯é€‰æä¾›ï¼Œå·¥å…·å†…éƒ¨ä¼šè‡ªåŠ¨å…œåº•
        **({"results_dir": state.results_dir} if state.results_dir else {}),
        # æ·»åŠ stateä¿¡æ¯ç”¨äºå‚æ•°ç‰ˆæœ¬åŒ–
        "state_info": {
            "results_dir": state.results_dir,
            "results_timestamp": state.results_timestamp
        }
    }
    
    user_context = {
        "execution_mode": state.execution_mode,
        "sample_info": sample_info,
        "nextflow_config": state.nextflow_config,
        "current_featurecounts_params": state.featurecounts_params,
        "star_results": state.star_results,
        "hisat2_results": getattr(state, 'hisat2_results', {}),
        "genome_version": state.nextflow_config.get("genome_version", ""),
        "optimization_history": {
            "featurecounts": state.featurecounts_optimization_history,  # å®Œæ•´å†å²åˆ—è¡¨
            "star": state.star_optimization_params,                     # æš‚æ—¶ä¿æŒå…¼å®¹
            "fastp": state.fastp_optimization_params,
        },
    }
    
    user_prompt = json.dumps(user_context, ensure_ascii=False, indent=2)
    
    # åˆ›å»ºå¹¶è°ƒç”¨Agent
    agent_executor = create_featurecounts_agent()
    
    # æ„å»ºæ¶ˆæ¯æ ¼å¼
    messages = [
        {"role": "user", "content": user_prompt}
    ]
    
    result = await agent_executor.ainvoke({"messages": messages})
    
    # æå–ç»“æ„åŒ–å“åº”
    structured_response = result.get("structured_response")
    try:
        if structured_response:
            log_llm_preview(logger, "featurecounts", structured_response)
        else:
            log_llm_preview(logger, "featurecounts.raw", {"keys": list(result.keys())[:10]})
    except Exception:
        pass
    if not structured_response:
        raise ValueError("Agentè¿”å›çš„ç»“æ„åŒ–å“åº”ä¸ºç©º")
    
    return structured_response
