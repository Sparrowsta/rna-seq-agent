import json
from typing import Dict, Any
from ..state import AgentState, PrepareResponse
from ..core import get_shared_llm
from ..prompts import PREPARE_NODE_PROMPT
from langgraph.prebuilt import create_react_agent

def create_prepare_agent(detection_context: str = ""):
    """åˆ›å»ºPrepareèŠ‚ç‚¹çš„æ™ºèƒ½é…ç½®Agent
    
    Args:
        detection_context: æ£€æµ‹æ•°æ®å’Œç”¨æˆ·éœ€æ±‚çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
    """
    llm = get_shared_llm()
    
    # æ„å»ºå®Œæ•´çš„promptï¼Œç»“åˆåŸºç¡€promptå’Œä¸Šä¸‹æ–‡
    if detection_context:
        full_prompt = PREPARE_NODE_PROMPT + "\n\n## å½“å‰åˆ†ææ•°æ®\n" + detection_context
    else:
        full_prompt = PREPARE_NODE_PROMPT
    
    # ä½¿ç”¨create_react_agentä½†ä¸æä¾›toolsï¼Œçº¯æ¨ç†æ¨¡å¼
    agent = create_react_agent(
        model=llm,
        tools=[],  # ç©ºå·¥å…·åˆ—è¡¨ï¼Œçº¯æ¨ç†
        prompt=full_prompt,  # ä½¿ç”¨åŠ¨æ€æ„å»ºçš„å®Œæ•´prompt
        response_format=PrepareResponse
    )
    return agent

async def prepare_node(state: AgentState) -> Dict[str, Any]:
    """å‡†å¤‡èŠ‚ç‚¹ - ä¼˜å…ˆåŸºäºNormalæ¨¡å¼ä¼ æ¥çš„ç”¨æˆ·éœ€æ±‚ç”Ÿæˆé…ç½®å‚æ•°"""
    print(f"âš™ï¸ å¼€å§‹æ™ºèƒ½é…ç½®åˆ†æ...")
    
    # è·å–æ‰€æœ‰å¿…è¦ä¿¡æ¯
    detection_results = state.query_results or {}
    current_config = state.nextflow_config or {}
    initial_requirements = state.user_requirements or {}
    replan_requirements = state.replan_requirements or {}
    
    if not detection_results:
        return {
            "nextflow_config": current_config,
            "resource_config": {},
            "config_reasoning": "æœªè·å–åˆ°æ£€æµ‹æ•°æ®ï¼Œä¿æŒç°æœ‰é…ç½®",
            "response": "âš ï¸ ç¼ºå°‘æ£€æµ‹æ•°æ®ï¼Œæ— æ³•è¿›è¡Œæ™ºèƒ½é…ç½®åˆ†æ",
            "status": "error"
        }
    
    # ä½¿ç”¨LLMç»¼åˆåˆ†æç”¨æˆ·éœ€æ±‚å’Œæ£€æµ‹æ•°æ®
    
    try:
        print("ğŸ§  LLMæ­£åœ¨åŸºäºç”¨æˆ·éœ€æ±‚åˆ†ææ£€æµ‹æ•°æ®å¹¶ç”Ÿæˆé…ç½®...")
        
        # æ„å»ºéœ€æ±‚ä¸Šä¸‹æ–‡
        context_parts = []
        if initial_requirements:
            context_parts.append(f"åˆå§‹é…ç½®éœ€æ±‚: {initial_requirements}")
        if replan_requirements:
            context_parts.append(f"é‡æ–°è§„åˆ’éœ€æ±‚: {replan_requirements} (ä¼˜å…ˆçº§æ›´é«˜)")
        
        # æ·»åŠ æ£€æµ‹æ•°æ®
        context_parts.append(f"=== ğŸ“Š ç³»ç»Ÿæ£€æµ‹æ•°æ® ===")
        context_parts.append(json.dumps(detection_results, indent=2, ensure_ascii=False))
        
        # æ·»åŠ å½“å‰é…ç½®çŠ¶æ€
        context_parts.append(f"=== âš™ï¸ å½“å‰é…ç½®çŠ¶æ€ ===")
        context_parts.append(json.dumps(current_config, indent=2, ensure_ascii=False))
        
        detection_context = "\n".join(context_parts)
        
        # å°†ä¸Šä¸‹æ–‡ä¼ é€’ç»™create_prepare_agent
        agent_executor = create_prepare_agent(detection_context)
        
        # ç®€å•çš„ç”¨æˆ·æ¶ˆæ¯
        user_message = "è¯·åŸºäºç”¨æˆ·éœ€æ±‚å’Œæ£€æµ‹æ•°æ®ç”Ÿæˆæœ€ä¼˜é…ç½®"
        messages_input = {"messages": [{"role": "user", "content": user_message}]}
        
        result = await agent_executor.ainvoke(messages_input)
        structured_response = result.get("structured_response")

        # æ£€æŸ¥LLMå“åº”å¹¶æå–ç»“æœï¼ˆä¸¥æ ¼éµå¾ª PrepareResponse çš„å­—æ®µï¼šnextflow_config/resource_config/config_reasoningï¼‰
        if structured_response:
            reasoning = structured_response.config_reasoning or "åŸºäºç”¨æˆ·éœ€æ±‚å’Œæ£€æµ‹æ•°æ®çš„æ™ºèƒ½åˆ†æ"

            nextflow_cfg = structured_response.nextflow_config or {}
            resource_params = structured_response.resource_config or {}

            print(f"âœ… é…ç½®ç”Ÿæˆå®Œæˆï¼Œä¸¥æ ¼éµå¾ªç”¨æˆ·éœ€æ±‚")

            # åˆå¹¶é…ç½®å‚æ•°ï¼ˆæ–°é…ç½®ä¼˜å…ˆï¼‰
            final_config = current_config.copy()
            final_config.update(nextflow_cfg)

            # æ„å»ºéœ€æ±‚æ»¡è¶³æƒ…å†µè¯´æ˜
            user_satisfaction_note = ""
            if initial_requirements or replan_requirements:
                satisfaction_parts = []
                if initial_requirements:
                    satisfaction_parts.append(f"åˆå§‹éœ€æ±‚: {initial_requirements}")
                if replan_requirements:
                    satisfaction_parts.append(f"é‡æ–°è§„åˆ’éœ€æ±‚: {replan_requirements} (å·²ä¼˜å…ˆåº”ç”¨)")
                user_satisfaction_note = f"\n\nğŸ¯ **ç”¨æˆ·éœ€æ±‚æ»¡è¶³æƒ…å†µï¼š**\n" + "\n".join(satisfaction_parts)

            return {
                "nextflow_config": final_config,
                "resource_config": resource_params,  # æ˜¾å¼ä¼ é€’èµ„æºé…ç½®ï¼Œä¾› execute_node ç”Ÿæˆ nextflow.config
                "config_reasoning": reasoning,
                "response": f"æ™ºèƒ½é…ç½®åˆ†æå®Œæˆ{user_satisfaction_note}\n\nğŸ’¡ {reasoning}",
                "status": "confirm"
            }
        else:
            raise Exception("Agentæœªè¿”å›é¢„æœŸçš„ç»“æ„åŒ–å“åº”")
        
    except Exception as e:
        print(f"âŒ LLMåˆ†æå¤±è´¥: {str(e)}")
        return {
            "nextflow_config": current_config,
            "resource_config": {},
            "config_reasoning": f"LLMåˆ†æå¤±è´¥: {str(e)}",
            "response": f"âŒ é…ç½®ç”Ÿæˆå¤±è´¥: {str(e)}",
            "status": "error"
        }
