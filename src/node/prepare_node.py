import json
from typing import Dict, Any
from ..state import AgentState, PrepareResponse
from ..core import get_shared_llm
from ..prompts import PREPARE_NODE_PROMPT
from langgraph.prebuilt import create_react_agent
from ..tools import (
    scan_fastq_files,
    scan_system_resources,
    scan_genome_files,
    check_tool_availability,
    get_project_overview,
)

def create_prepare_agent(detection_context: str = ""):
    """åˆ›å»ºPrepareèŠ‚ç‚¹çš„æ™ºèƒ½é…ç½®Agent
    
    Args:
        detection_context: æ£€æµ‹æ•°æ®å’Œç”¨æˆ·éœ€æ±‚çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
    """
    llm = get_shared_llm()
    
    # æ„å»ºå®Œæ•´çš„promptï¼Œç»“åˆåŸºç¡€promptå’Œä¸Šä¸‹æ–‡
    if detection_context:
        full_prompt = PREPARE_NODE_PROMPT + "\n\n## å½“å‰åˆ†ææ•°æ®\n" + detection_context
    else:
        full_prompt = PREPARE_NODE_PROMPT
    
    # ä½¿ç”¨create_react_agentå¹¶æŒ‚è½½æ£€æµ‹ç›¸å…³å·¥å…·ï¼Œå…è®¸æŒ‰éœ€å†æ£€æµ‹
    agent = create_react_agent(
        model=llm,
        tools=[
            scan_fastq_files,
            scan_system_resources,
            scan_genome_files,
            check_tool_availability,
            get_project_overview,
        ],
        prompt=full_prompt,  # ä½¿ç”¨åŠ¨æ€æ„å»ºçš„å®Œæ•´prompt
        response_format=PrepareResponse
    )
    return agent


async def prepare_node(state: AgentState) -> Dict[str, Any]:
    """å‡†å¤‡èŠ‚ç‚¹ - ä¸“æ³¨äºåˆå§‹é…ç½®ç”Ÿæˆï¼ŒåŸºäºç”¨æˆ·éœ€æ±‚å’Œæ£€æµ‹æ•°æ®"""
    print(f"âš™ï¸ å¼€å§‹æ™ºèƒ½é…ç½®åˆ†æ...")
    
    # è·å–æ ¸å¿ƒä¿¡æ¯
    detection_results = state.query_results or {}
    initial_requirements = state.user_requirements or {}
    
    if not detection_results:
        return {
            "success": False,
            "nextflow_config": {},
            "resource_config": {},
            "config_reasoning": "æœªè·å–åˆ°æ£€æµ‹æ•°æ®ï¼Œæ— æ³•è¿›è¡Œæ™ºèƒ½é…ç½®åˆ†æ",
            "response": "âš ï¸ ç¼ºå°‘æ£€æµ‹æ•°æ®ï¼Œæ— æ³•è¿›è¡Œæ™ºèƒ½é…ç½®åˆ†æ",
            "status": "failed"
        }
    
    # ä½¿ç”¨LLMç»¼åˆåˆ†æç”¨æˆ·éœ€æ±‚å’Œæ£€æµ‹æ•°æ®
    try:
        print("ğŸ§  LLMæ­£åœ¨åŸºäºç”¨æˆ·éœ€æ±‚åˆ†ææ£€æµ‹æ•°æ®å¹¶ç”Ÿæˆåˆå§‹é…ç½®...")
        
        # æ„å»ºä¸Šä¸‹æ–‡ï¼ˆä»…åŒ…å«åˆå§‹éœ€æ±‚ï¼Œä¸å¤„ç†ä¿®æ”¹ï¼‰
        context_parts = []
        if initial_requirements:
            context_parts.append(f"**ç”¨æˆ·éœ€æ±‚**: {initial_requirements}")
        
        # æ·»åŠ æ£€æµ‹æ•°æ®
        context_parts.append(f"=== ğŸ“Š ç³»ç»Ÿæ£€æµ‹æ•°æ® ===")
        context_parts.append(json.dumps(detection_results, indent=2, ensure_ascii=False))
        
        detection_context = "\n".join(context_parts)
        
        # å°†ä¸Šä¸‹æ–‡ä¼ é€’ç»™create_prepare_agent
        agent_executor = create_prepare_agent(detection_context)
        
        # æ„å»ºç”¨æˆ·æ¶ˆæ¯
        user_message = "è¯·åŸºäºç”¨æˆ·éœ€æ±‚å’Œæ£€æµ‹æ•°æ®ç”Ÿæˆæœ€ä¼˜åˆå§‹é…ç½®"
        messages_input = {"messages": [{"role": "user", "content": user_message}]}
        
        result = await agent_executor.ainvoke(messages_input)
        structured_response = result.get("structured_response")

        # æ£€æŸ¥LLMå“åº”å¹¶æå–ç»“æœ
        if structured_response:
            reasoning = structured_response.config_reasoning or "åŸºäºç”¨æˆ·éœ€æ±‚å’Œæ£€æµ‹æ•°æ®çš„æ™ºèƒ½åˆ†æ"

            nextflow_cfg = structured_response.nextflow_config or {}
            resource_params = structured_response.resource_config or {}

            print(f"âœ… åˆå§‹é…ç½®ç”Ÿæˆå®Œæˆ")

            # æ„å»ºç”¨æˆ·éœ€æ±‚æ»¡è¶³è¯´æ˜
            user_satisfaction_note = ""
            if initial_requirements:
                user_satisfaction_note = f"\n\nğŸ¯ **ç”¨æˆ·éœ€æ±‚å¤„ç†æƒ…å†µï¼š**\nğŸ“‹ {initial_requirements}"

            return {
                "success": True,
                "nextflow_config": nextflow_cfg,
                "resource_config": resource_params,
                "config_reasoning": reasoning,
                "response": f"æ™ºèƒ½é…ç½®åˆ†æå®Œæˆ{user_satisfaction_note}\n\nğŸ’¡ {reasoning}",
                "status": "success"
            }
        else:
            raise Exception("Agentæœªè¿”å›é¢„æœŸçš„ç»“æ„åŒ–å“åº”")
        
    except Exception as e:
        print(f"âŒ é…ç½®ç”Ÿæˆå¤±è´¥: {str(e)}")
        return {
            "success": False,
            "nextflow_config": {},
            "resource_config": {},
            "config_reasoning": f"é…ç½®ç”Ÿæˆå¤±è´¥: {str(e)}",
            "response": f"âŒ é…ç½®ç”Ÿæˆå¤±è´¥: {str(e)}",
            "status": "failed"
        }
