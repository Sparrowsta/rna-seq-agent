import json
import re
from typing import Dict, Any
from pathlib import Path

from ..core import get_shared_llm
from ..state import AgentState, AnalysisResponse


def extract_nextflow_metrics(data_dir: str = ".") -> Dict[str, Any]:
    """æå–Nextflowæ‰§è¡ŒæŒ‡æ ‡ - ä»results/nextflow/trace.txtè¯»å–"""
    metrics = {}
    
    # æ›´æ–°traceæ–‡ä»¶è·¯å¾„
    trace_file = Path(data_dir) / "results" / "nextflow" / "execution_trace.txt"
    
    try:
        # ä¸»è¦ä»traceæ–‡ä»¶åˆ†ææ‰§è¡ŒçŠ¶æ€
        if trace_file.exists():
            with open(trace_file, 'r', encoding='utf-8') as f:
                trace_content = f.read()
                
            # ç»Ÿè®¡è¿›ç¨‹æ‰§è¡Œæƒ…å†µ
            lines = trace_content.strip().split('\n')
            if len(lines) > 1:  # è·³è¿‡è¡¨å¤´
                process_stats = {"total": 0, "completed": 0, "failed": 0, "cached": 0}
                for line in lines[1:]:
                    if line.strip():  # å¿½ç•¥ç©ºè¡Œ
                        parts = line.split('\t')
                        if len(parts) >= 5:  # ç¡®ä¿æœ‰statusåˆ—
                            status = parts[4].strip()  # statusåˆ—(0-based: task_id,hash,native_id,name,status)
                            process_stats["total"] += 1
                            if status == "COMPLETED":
                                process_stats["completed"] += 1
                            elif status == "FAILED":
                                process_stats["failed"] += 1
                            elif status == "CACHED":
                                process_stats["cached"] += 1
                                
                metrics["process_stats"] = process_stats
                
                # åŸºäºè¿›ç¨‹ç»Ÿè®¡æ¨æ–­å·¥ä½œæµçŠ¶æ€
                if process_stats["failed"] > 0:
                    metrics["workflow_status"] = "failed"
                elif process_stats["total"] > 0 and (process_stats["completed"] + process_stats["cached"]) == process_stats["total"]:
                    metrics["workflow_status"] = "success"
                else:
                    metrics["workflow_status"] = "running"
        else:
            # å¦‚æœtraceæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè®¾ä¸ºæœªçŸ¥çŠ¶æ€
            metrics["workflow_status"] = "unknown"
                
    except (FileNotFoundError, UnicodeDecodeError, IndexError) as e:
        # å¦‚æœæŠ¥å‘Šæ–‡ä»¶ä¸å­˜åœ¨æˆ–è¯»å–å¤±è´¥ï¼Œå›é€€åˆ°æœªçŸ¥çŠ¶æ€
        metrics["workflow_status"] = "unknown"
    
    return metrics


def extract_fastp_metrics(data_dir: str = ".") -> Dict[str, Any]:
    """æå–fastpè´¨æ§æŒ‡æ ‡ - ç›´æ¥è¯»å–JSONæŠ¥å‘Šæ–‡ä»¶"""
    metrics = {}
    
    fastp_dir = Path(data_dir) / "results" / "fastp"
    if not fastp_dir.exists():
        return metrics
    
    # åˆå¹¶æ‰€æœ‰æ ·æœ¬çš„fastpç»Ÿè®¡
    total_before_reads = 0
    total_after_reads = 0
    total_before_bases = 0
    total_after_bases = 0
    total_q30_before = 0
    total_q30_after = 0 
    total_q20_before = 0
    total_q20_after = 0
    total_low_quality = 0
    total_too_many_n = 0
    total_too_short = 0
    total_duplication_reads = 0
    insert_sizes = []
    sample_count = 0
    
    for sample_dir in fastp_dir.iterdir():
        if not sample_dir.is_dir():
            continue
            
        json_files = list(sample_dir.glob("*.fastp.json"))
        if json_files:
            try:
                with open(json_files[0], 'r') as f:
                    data = json.load(f)
                    summary = data.get("summary", {})
                    filtering = data.get("filtering_result", {})
                    duplication = data.get("duplication", {})
                    insert_size = data.get("insert_size", {})
                    
                    before = summary.get("before_filtering", {})
                    after = summary.get("after_filtering", {})
                    
                    # åŸºç¡€ç»Ÿè®¡
                    before_reads = before.get("total_reads", 0)
                    after_reads = after.get("total_reads", 0)
                    total_before_reads += before_reads
                    total_after_reads += after_reads
                    total_before_bases += before.get("total_bases", 0)
                    total_after_bases += after.get("total_bases", 0)
                    
                    # è´¨é‡æŒ‡æ ‡
                    total_q30_before += before.get("q30_bases", 0)
                    total_q30_after += after.get("q30_bases", 0)
                    total_q20_before += before.get("q20_bases", 0)
                    total_q20_after += after.get("q20_bases", 0)
                    
                    # è¿‡æ»¤ç»Ÿè®¡
                    total_low_quality += filtering.get("low_quality_reads", 0)
                    total_too_many_n += filtering.get("too_many_N_reads", 0)
                    total_too_short += filtering.get("too_short_reads", 0)
                    
                    # é‡å¤ç‡ç»Ÿè®¡
                    if before_reads > 0:
                        total_duplication_reads += int(before_reads * duplication.get("rate", 0))
                    
                    # æ’å…¥ç‰‡æ®µå¤§å°
                    if insert_size.get("peak"):
                        insert_sizes.append(insert_size.get("peak"))
                    
                    sample_count += 1
                    
            except (json.JSONDecodeError, FileNotFoundError, KeyError):
                continue
    
    if sample_count > 0:
        metrics["total_samples"] = sample_count
        metrics["total_before_reads"] = total_before_reads
        metrics["total_after_reads"] = total_after_reads
        metrics["total_before_bases"] = total_before_bases  
        metrics["total_after_bases"] = total_after_bases
        
        # è¿‡æ»¤ç‡
        metrics["filtering_rate"] = f"{((total_before_reads - total_after_reads) / total_before_reads * 100):.1f}%" if total_before_reads > 0 else "0%"
        
        # è´¨é‡ç‡ (Q30/Q20)
        metrics["q30_rate_before"] = f"{(total_q30_before / total_before_bases * 100):.1f}%" if total_before_bases > 0 else "0%"
        metrics["q30_rate_after"] = f"{(total_q30_after / total_after_bases * 100):.1f}%" if total_after_bases > 0 else "0%"
        metrics["q20_rate_before"] = f"{(total_q20_before / total_before_bases * 100):.1f}%" if total_before_bases > 0 else "0%"
        metrics["q20_rate_after"] = f"{(total_q20_after / total_after_bases * 100):.1f}%" if total_after_bases > 0 else "0%"
        
        # é‡å¤ç‡
        metrics["duplication_rate"] = f"{(total_duplication_reads / total_before_reads * 100):.1f}%" if total_before_reads > 0 else "0%"
        
        # è¿‡æ»¤åŸå› ç»Ÿè®¡
        metrics["low_quality_reads"] = total_low_quality
        metrics["too_many_n_reads"] = total_too_many_n
        metrics["too_short_reads"] = total_too_short
        
        # æ’å…¥ç‰‡æ®µå¤§å°
        if insert_sizes:
            metrics["average_insert_size"] = int(sum(insert_sizes) / len(insert_sizes))
    
    return metrics


def extract_star_metrics(data_dir: str = ".") -> Dict[str, Any]:
    """æå–STARæ¯”å¯¹æŒ‡æ ‡ - ä»Log.final.outæ–‡ä»¶è¯»å–"""
    metrics = {}
    
    star_dir = Path(data_dir) / "results" / "bam"
    if not star_dir.exists():
        return metrics
    
    # åˆå¹¶æ‰€æœ‰æ ·æœ¬çš„STARç»Ÿè®¡
    total_input_reads = 0
    total_uniquely_mapped = 0
    total_multimapped = 0
    total_unmapped = 0
    sample_count = 0
    
    for sample_dir in star_dir.iterdir():
        if not sample_dir.is_dir():
            continue
            
        log_files = list(sample_dir.glob("*.star.log"))
        if log_files:
            try:
                with open(log_files[0], 'r', encoding='utf-8') as f:
                    log_content = f.read()
                
                # æå–å…³é”®ç»Ÿè®¡æŒ‡æ ‡
                patterns = {
                    "input_reads": r'Number of input reads \|\s+(\d+)',
                    "uniquely_mapped": r'Uniquely mapped reads number \|\s+(\d+)',
                    "uniquely_mapped_pct": r'Uniquely mapped reads % \|\s+([\d.]+)%',
                    "multimapped_number": r'Number of reads mapped to multiple loci \|\s+(\d+)', 
                    "multimapped_pct": r'% of reads mapped to multiple loci \|\s+([\d.]+)%',
                    "unmapped_number": r'Number of reads unmapped: too many mismatches \|\s+(\d+)',
                    "unmapped_pct": r'% of reads unmapped: too many mismatches \|\s+([\d.]+)%'
                }
                
                sample_metrics = {}
                for key, pattern in patterns.items():
                    match = re.search(pattern, log_content)
                    if match:
                        sample_metrics[key] = match.group(1)
                
                # ç´¯åŠ ç»Ÿè®¡
                if "input_reads" in sample_metrics:
                    reads = int(sample_metrics["input_reads"])
                    total_input_reads += reads
                    
                if "uniquely_mapped" in sample_metrics:
                    total_uniquely_mapped += int(sample_metrics["uniquely_mapped"])
                    
                if "multimapped_number" in sample_metrics:
                    total_multimapped += int(sample_metrics["multimapped_number"])
                    
                if "unmapped_number" in sample_metrics:
                    total_unmapped += int(sample_metrics["unmapped_number"])
                
                sample_count += 1
                    
            except (FileNotFoundError, ValueError, AttributeError):
                continue
    
    # è®¡ç®—æ€»ä½“ç»Ÿè®¡
    if sample_count > 0 and total_input_reads > 0:
        metrics["total_samples"] = sample_count
        metrics["total_input_reads"] = total_input_reads
        metrics["uniquely_mapped_reads"] = total_uniquely_mapped
        metrics["multimapped_reads"] = total_multimapped
        metrics["unmapped_reads"] = total_unmapped
        
        # è®¡ç®—ç™¾åˆ†æ¯”
        metrics["uniquely_mapped_rate"] = f"{(total_uniquely_mapped / total_input_reads * 100):.1f}%"
        metrics["multimapped_rate"] = f"{(total_multimapped / total_input_reads * 100):.1f}%"
        metrics["unmapped_rate"] = f"{(total_unmapped / total_input_reads * 100):.1f}%"
        metrics["total_mapped_rate"] = f"{((total_uniquely_mapped + total_multimapped) / total_input_reads * 100):.1f}%"
    
    return metrics


def extract_featurecounts_metrics(data_dir: str = ".") -> Dict[str, Any]:
    """æå–featureCountså®šé‡æŒ‡æ ‡ - ä½¿ç”¨pandasè¯»å–summaryæ–‡ä»¶"""
    metrics = {}
    
    summary_file = Path(data_dir) / "results" / "featurecounts" / "all_samples.counts.txt.summary"
    if not summary_file.exists():
        return metrics
    
    try:
        import pandas as pd
        
        # ç”¨pandasè¯»å–TSVæ–‡ä»¶
        df = pd.read_csv(summary_file, sep='\t')
        
        # ä¿å­˜åŸå§‹è¡¨æ ¼å†…å®¹
        metrics["raw_summary"] = df.to_string(index=False)
        
        # è½¬ä¸ºå­—å…¸æ ¼å¼
        sample_columns = [col for col in df.columns if col != 'Status']
        metrics["sample_count"] = len(sample_columns)
        
        # æ±‡æ€»æ‰€æœ‰æ ·æœ¬çš„ç»Ÿè®¡
        summary_data = {}
        for _, row in df.iterrows():
            status = row['Status']
            total_count = row[sample_columns].sum()
            summary_data[status] = int(total_count)
        
        metrics["summary_data"] = summary_data
        
        # åŸºæœ¬ç»Ÿè®¡
        assigned = summary_data.get("Assigned", 0)
        total_reads = sum(summary_data.values())
        metrics["assigned_reads"] = assigned
        metrics["total_processed_reads"] = total_reads
        metrics["assignment_rate"] = f"{(assigned / total_reads * 100):.1f}%" if total_reads > 0 else "0%"
        
    except (ImportError, FileNotFoundError, ValueError, KeyError):
        # å¦‚æœpandasä¸å¯ç”¨æˆ–æ–‡ä»¶è¯»å–å¤±è´¥ï¼Œå›é€€åˆ°åŸºç¡€æ–¹æ³•
        try:
            with open(summary_file, 'r') as f:
                file_content = f.read().strip()
            metrics["raw_summary"] = file_content
        except:
            pass
    
    return metrics


def save_analysis_report(analysis_response: AnalysisResponse, data_dir: str = ".") -> Dict[str, str]:
    """ä¿å­˜åˆ†ææŠ¥å‘Šåˆ°reportsç›®å½•"""
    import datetime
    
    reports_path = Path(data_dir) / "reports"
    reports_path.mkdir(exist_ok=True)
    
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    saved_files = {}
    
    try:
        # 1. ä¿å­˜JSONæ ¼å¼çš„å®Œæ•´æ•°æ®
        json_file = reports_path / f"analysis_report_{timestamp}.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump({
                "timestamp": timestamp,
                "analysis_summary": analysis_response.analysis_summary,
                "analysis_insights": analysis_response.analysis_insights,
                "result_files": analysis_response.result_files,
                "quality_metrics": analysis_response.quality_metrics,
                "next_steps": analysis_response.next_steps
            }, f, ensure_ascii=False, indent=2)
        saved_files["json"] = str(json_file.relative_to(Path(data_dir)))
        
        # 2. ä¿å­˜Markdownæ ¼å¼çš„å¯è¯»æŠ¥å‘Š
        md_file = reports_path / f"analysis_summary_{timestamp}.md"
        with open(md_file, 'w', encoding='utf-8') as f:
            f.write(f"# RNA-seq åˆ†ææŠ¥å‘Š\n\n")
            f.write(f"**ç”Ÿæˆæ—¶é—´**: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write(f"## åˆ†ææ€»ç»“\n\n{analysis_response.analysis_summary}\n\n")
            
            if analysis_response.analysis_insights:
                f.write(f"## åˆ†ææ´å¯Ÿ\n\n")
                for insight in analysis_response.analysis_insights:
                    f.write(f"- {insight}\n")
                f.write(f"\n")
            
            if analysis_response.result_files:
                f.write(f"## ç»“æœæ–‡ä»¶\n\n")
                for category, path in analysis_response.result_files.items():
                    f.write(f"- **{category}**: `{path}`\n")
                f.write(f"\n")
            
            if analysis_response.next_steps:
                f.write(f"## ä¸‹ä¸€æ­¥å»ºè®®\n\n")
                for step in analysis_response.next_steps:
                    f.write(f"- {step}\n")
        saved_files["markdown"] = str(md_file.relative_to(Path(data_dir)))
        
        # 3. ä¿å­˜æœ€æ–°æŠ¥å‘Šçš„ç¬¦å·é“¾æ¥
        latest_json = results_path / "analysis_report_latest.json"
        latest_md = results_path / "analysis_summary_latest.md"
        
        # åˆ é™¤æ—§çš„ç¬¦å·é“¾æ¥(å¦‚æœå­˜åœ¨)
        if latest_json.is_symlink():
            latest_json.unlink()
        if latest_md.is_symlink():
            latest_md.unlink()
            
        # åˆ›å»ºæ–°çš„ç¬¦å·é“¾æ¥
        latest_json.symlink_to(json_file.name)
        latest_md.symlink_to(md_file.name)
        
        saved_files["latest_json"] = str(latest_json.relative_to(Path(data_dir)))
        saved_files["latest_md"] = str(latest_md.relative_to(Path(data_dir)))
        
    except Exception as e:
        print(f"ä¿å­˜åˆ†ææŠ¥å‘Šæ—¶å‡ºé”™: {e}")
    
    return saved_files


def scan_result_files(data_dir: str = ".") -> Dict[str, Any]:
    """æ‰«æå¹¶ç»Ÿè®¡ç»“æœæ–‡ä»¶"""
    file_stats = {
        "total_files": 0,
        "file_categories": {},
        "key_files": {}
    }
    
    results_path = Path(data_dir) / "results"
    if not results_path.exists():
        return file_stats
    
    # å®šä¹‰æ–‡ä»¶ç±»åˆ«
    categories = {
        "quality_reports": [".html", ".json"],
        "alignment_files": [".bam", ".sam"],
        "quantification": [".txt", ".tsv", ".counts"],
        "logs": [".log", ".out", ".err"]
    }
    
    all_files = list(results_path.rglob("*"))
    file_stats["total_files"] = len([f for f in all_files if f.is_file()])
    
    for category, extensions in categories.items():
        category_files = []
        for ext in extensions:
            category_files.extend([f for f in all_files if f.suffix == ext])
        
        file_stats["file_categories"][category] = len(category_files)
        if category_files:
            # è®°å½•ç¬¬ä¸€ä¸ªæ–‡ä»¶ä½œä¸ºä»£è¡¨
            file_stats["key_files"][category] = str(category_files[0].relative_to(Path(data_dir)))
    
    return file_stats


async def map_analysis_to_agent_state(analysis_response: AnalysisResponse, state: AgentState) -> Dict[str, Any]:
    """å°†AnalysisResponseæ˜ å°„åˆ°å®Œæ•´çš„AgentState"""
    return {
        "messages": state.messages,
        "input": state.input,
        "response": analysis_response.analysis_summary,
        "status": "analysis_complete",
        "analysis_summary": analysis_response.analysis_summary,
        "analysis_insights": analysis_response.analysis_insights,
        "result_files": analysis_response.result_files,
        "quality_metrics": analysis_response.quality_metrics,
        "next_steps": analysis_response.next_steps,
        # ä¿æŒæ‰§è¡ŒçŠ¶æ€
        "execution_status": state.execution_status,
        "execution_output": state.execution_output,
        "execution_result": state.execution_result,
        "nextflow_config": state.nextflow_config,
    }


async def analysis_node(state: AgentState) -> Dict[str, Any]:
    """
    AnalysisèŠ‚ç‚¹ - æå–å…³é”®æŒ‡æ ‡å¹¶è®©LLMç”Ÿæˆæ™ºèƒ½åˆ†ææ€»ç»“
    
    æ¶æ„ï¼š
    1. ä»æ‰§è¡Œè¾“å‡ºä¸­æå–å…·ä½“æŒ‡æ ‡
    2. æ‰«æç»“æœæ–‡ä»¶ç»Ÿè®¡
    3. å°†ç»“æ„åŒ–æŒ‡æ ‡äº¤ç»™LLMåˆ†æ
    4. LLMç”Ÿæˆä¸“ä¸šçš„æ€»ç»“å’Œå»ºè®®
    """
    
    execution_output = getattr(state, 'execution_output', '')
    execution_status = getattr(state, 'execution_status', '')
    nextflow_config = getattr(state, 'nextflow_config', {})
    
    # 1. æå–å„å·¥å…·çš„å…·ä½“æŒ‡æ ‡  
    data_dir = "."  # Dockerå®¹å™¨å†…å½“å‰ç›®å½•å°±æ˜¯/data
    extracted_metrics = {
        "nextflow": extract_nextflow_metrics(data_dir),
        "fastp": extract_fastp_metrics(data_dir),
        "star": extract_star_metrics(data_dir), 
        "featurecounts": extract_featurecounts_metrics(data_dir),
        "file_stats": scan_result_files(data_dir)
    }
    
    # 2. å‡†å¤‡é…ç½®ä¿¡æ¯ä¸Šä¸‹æ–‡
    analysis_context = {
        "execution_status": execution_status,
        "tools_used": {
            "qc_tool": nextflow_config.get("qc_tool", "unknown"),
            "align_tool": nextflow_config.get("align_tool", "unknown"),
            "quant_tool": nextflow_config.get("quant_tool", "unknown"),
            "genome_version": nextflow_config.get("genome_version", "unknown")
        },
        "extracted_metrics": extracted_metrics
    }
    
    # 3. è®©LLMåŸºäºå…·ä½“æŒ‡æ ‡ç”Ÿæˆä¸“ä¸šåˆ†æ
    llm = get_shared_llm()
    structured_llm = llm.with_structured_output(AnalysisResponse, method="json_mode")
    
    analysis_prompt = f"""ä½ æ˜¯RNA-seqæ•°æ®åˆ†æä¸“å®¶ã€‚è¯·åŸºäºä»¥ä¸‹å…·ä½“çš„æŠ€æœ¯æŒ‡æ ‡ç”Ÿæˆä¸“ä¸šçš„åˆ†ææ€»ç»“æŠ¥å‘Šã€‚

## åˆ†æé…ç½®
{json.dumps(analysis_context["tools_used"], ensure_ascii=False, indent=2)}

## æ‰§è¡ŒçŠ¶æ€
{execution_status}

## å…·ä½“æŠ€æœ¯æŒ‡æ ‡
{json.dumps(extracted_metrics, ensure_ascii=False, indent=2)}

è¯·ç”Ÿæˆä¸“ä¸šçš„RNA-seqåˆ†ææŠ¥å‘Šï¼ŒåŒ…å«ï¼š

1. **analysis_summary**: åŸºäºå…·ä½“æŒ‡æ ‡çš„æ€»ç»“(3-4å¥è¯ï¼Œçªå‡ºå…³é”®æ•°å€¼)
   - å¦‚æœæœ‰æ¯”å¯¹ç‡ï¼Œè¯´æ˜æ¯”å¯¹æ•ˆæœ
   - å¦‚æœæœ‰è´¨æ§æ•°æ®ï¼Œè¯„ä¼°æ•°æ®è´¨é‡
   - å¦‚æœæœ‰å®šé‡ç»“æœï¼Œè¯´æ˜åŸºå› æ£€å‡ºæƒ…å†µ

2. **analysis_insights**: åŸºäºæ•°å€¼çš„ä¸“ä¸šæ´å¯Ÿ(æ¯æ¡åŒ…å«å…·ä½“æ•°æ®)
   - ä¾‹å¦‚ï¼š"âœ… STARæ¯”å¯¹æˆåŠŸç‡è¾¾åˆ°85.2%ï¼Œè¡¨æ˜æ ·æœ¬ä¸å‚è€ƒåŸºå› ç»„åŒ¹é…è‰¯å¥½"
   - ä¾‹å¦‚ï¼š"ğŸ“Š featureCountsæˆåŠŸåˆ†é…äº†2,345,678æ¡readsåˆ°åŸºå› ç‰¹å¾"

3. **result_files**: é‡è¦ç»“æœæ–‡ä»¶è·¯å¾„
4. **quality_metrics**: å…³é”®è´¨é‡æŒ‡æ ‡çš„ç»“æ„åŒ–æ•°æ®
5. **next_steps**: åŸºäºå½“å‰ç»“æœçš„å…·ä½“å»ºè®®

è¦æ±‚ï¼š
- ä½¿ç”¨ä¸­æ–‡
- åŸºäºå®é™…æ•°å€¼è¿›è¡Œè¯„ä¼°
- å¦‚æœæŸä¸ªæŒ‡æ ‡å¼‚å¸¸ï¼Œæ˜ç¡®æŒ‡å‡ºé—®é¢˜
- æä¾›å…·ä½“å¯è¡Œçš„æ”¹è¿›å»ºè®®
- è¾“å‡ºJSONæ ¼å¼
"""
    
    try:
        # LLMåŸºäºå…·ä½“æŒ‡æ ‡ç”Ÿæˆåˆ†æ
        raw_response = await structured_llm.ainvoke([{"role": "user", "content": analysis_prompt}])
        
        # ç¡®ä¿è¿”å›æ­£ç¡®çš„AnalysisResponseç±»å‹
        if isinstance(raw_response, dict):
            analysis_response = AnalysisResponse(**raw_response)
        else:
            analysis_response = raw_response
            
        # ç¡®ä¿æŠ€æœ¯æŒ‡æ ‡è¢«ä¿ç•™
        if not analysis_response.quality_metrics:
            analysis_response.quality_metrics = extracted_metrics
            
    except Exception as e:
        print(f"LLMåˆ†æå¤±è´¥: {e}")
        # å¤‡ç”¨å“åº”åŸºäºæå–çš„æŒ‡æ ‡
        analysis_response = AnalysisResponse(
            analysis_summary=f"åˆ†æå®Œæˆ({execution_status})ã€‚æ£€æµ‹åˆ°{len(extracted_metrics)}ç±»æŠ€æœ¯æŒ‡æ ‡ã€‚",
            analysis_insights=[f"å·¥å…·ç»„åˆ: {analysis_context['tools_used']}"],
            result_files=extracted_metrics.get("file_stats", {}).get("key_files", {}),
            quality_metrics=extracted_metrics,
            next_steps=["æ£€æŸ¥è¯¦ç»†çš„æŠ€æœ¯æŒ‡æ ‡è¿›è¡Œè¿›ä¸€æ­¥åˆ†æ"]
        )
    
    # 4. ä¿å­˜åˆ†ææŠ¥å‘Šåˆ°æ–‡ä»¶
    saved_files = save_analysis_report(analysis_response)
    print(f"âœ… åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {saved_files}")
    
    return await map_analysis_to_agent_state(analysis_response, state)