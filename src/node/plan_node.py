from typing import Dict, Any
from ..state import AgentState, PlanResponse
from ..core import get_shared_llm
from ..prompts import PLAN_NODE_PROMPT
from langgraph.prebuilt import create_react_agent

def create_plan_agent(requirements_context: str = ""):
    """åˆ›å»ºPlanèŠ‚ç‚¹çš„æ™ºèƒ½è§„åˆ’Agent
    
    Args:
        requirements_context: ç”¨æˆ·éœ€æ±‚å’ŒçŠ¶æ€çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
    """
    llm = get_shared_llm()
    
    # æž„å»ºå®Œæ•´çš„promptï¼Œç»“åˆåŸºç¡€promptå’Œä¸Šä¸‹æ–‡
    if requirements_context:
        full_prompt = PLAN_NODE_PROMPT + "\n\n## å½“å‰åˆ†æžä¸Šä¸‹æ–‡\n" + requirements_context
    else:
        full_prompt = PLAN_NODE_PROMPT
    
    # ä½¿ç”¨create_react_agentä½†ä¸æä¾›toolsï¼Œçº¯æŽ¨ç†æ¨¡å¼
    agent = create_react_agent(
        model=llm,
        tools=[],  # ç©ºå·¥å…·åˆ—è¡¨ï¼Œçº¯æŽ¨ç†
        prompt=full_prompt,  # ä½¿ç”¨åŠ¨æ€æž„å»ºçš„å®Œæ•´prompt
        response_format=PlanResponse
    )
    return agent

async def plan_node(state: AgentState) -> Dict[str, Any]:
    """å¢žå¼ºçš„PlanèŠ‚ç‚¹ - æ”¯æŒå¹¶è¡Œä»»åŠ¡ç»„è§„åˆ’"""
    
    # åˆ†åˆ«èŽ·å–ä¸¤ç§éœ€æ±‚
    initial_requirements = getattr(state, 'user_requirements', {})
    replan_requirements = getattr(state, 'replan_requirements', {})
    
    # åˆ¤æ–­æ˜¯å¦ä¸ºé‡æ–°è§„åˆ’
    is_replanning = bool(replan_requirements)
    
    # æž„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯
    context_parts = []
    if initial_requirements:
        context_parts.append(f"åˆå§‹é…ç½®éœ€æ±‚: {initial_requirements}")
    if replan_requirements:
        context_parts.append(f"é‡æ–°è§„åˆ’éœ€æ±‚: {replan_requirements}")
    
    # æ·»åŠ è§„åˆ’ç±»åž‹è¯´æ˜Ž
    if is_replanning:
        context_parts.append("è¿™æ˜¯ä¸€æ¬¡é‡æ–°è§„åˆ’ï¼Œè¯·åŸºäºŽæ–°çš„éœ€æ±‚è°ƒæ•´æ£€æµ‹è®¡åˆ’")
    else:
        context_parts.append("è¿™æ˜¯åˆå§‹è§„åˆ’ï¼Œè¯·ç”Ÿæˆå®Œæ•´çš„æ£€æµ‹ä»»åŠ¡è®¡åˆ’")
        
    # æ·»åŠ å½“å‰é…ç½®çŠ¶æ€
    if hasattr(state, 'nextflow_config') and state.nextflow_config:
        context_parts.append(f"å½“å‰é…ç½®çŠ¶æ€: {state.nextflow_config}")
    
    requirements_context = "\n".join(context_parts) if context_parts else ""
    
    try:
        # å°†ä¸Šä¸‹æ–‡ä¼ é€’ç»™create_plan_agent
        agent_executor = create_plan_agent(requirements_context)
        
        # ç®€å•çš„ç”¨æˆ·æ¶ˆæ¯
        user_message = "è¯·ç”Ÿæˆå¹¶è¡Œæ£€æµ‹ä»»åŠ¡è®¡åˆ’"
        messages_input = {"messages": [{"role": "user", "content": user_message}]}
        
        result = await agent_executor.ainvoke(messages_input)
        structured_response = result.get("structured_response")
        
        if structured_response:
            # æå–å¹¶è¡Œä»»åŠ¡ç»„ä¿¡æ¯
            task_groups = structured_response.plan or []
            group_descriptions = structured_response.group_descriptions or []
            execution_strategy = structured_response.execution_strategy or "parallel"
        
        if not task_groups:
            raise Exception("æœªç”Ÿæˆæœ‰æ•ˆçš„æ£€æµ‹è®¡åˆ’")
            
    except Exception as e:
        print(f"âŒ LLMè§„åˆ’å¤±è´¥: {e}")
        return {
            "plan": [],
            "group_descriptions": [],
            "execution_strategy": "sequential",
            "error": f"è§„åˆ’å¤±è´¥: {str(e)}"
        }
    
    # å¹³é“ºä»»åŠ¡ç»„ä¸ºæ£€æµ‹ä»»åŠ¡åˆ—è¡¨
    detection_tasks = []
    for group in task_groups:
        detection_tasks.extend(group)
    
    print(f"ðŸ“‹ ç”Ÿæˆæ£€æµ‹è®¡åˆ’: {len(task_groups)}ç»„å¹¶è¡Œä»»åŠ¡ï¼Œå…±{len(detection_tasks)}ä¸ªæ£€æµ‹é¡¹")
    for i, (group, desc) in enumerate(zip(task_groups, group_descriptions)):
        print(f"  ç»„{i+1}: {desc} -> {group}")
    
    return {
        "plan": task_groups,
        "group_descriptions": group_descriptions, 
        "execution_strategy": execution_strategy,
        "detection_tasks": detection_tasks,
        "is_replanning": is_replanning
    }