"""
FastPèŠ‚ç‚¹ - ç”¨äºæ‰§è¡ŒFastPè´¨é‡æ§åˆ¶
"""

from typing import Any, Dict
from langgraph.prebuilt import create_react_agent
from ..state import AgentState, FastpResponse
from ..core import get_shared_llm
from ..prompts import FASTP_OPTIMIZATION_PROMPT
from ..tools import (
    run_nextflow_fastp,
    parse_fastp_results
)
from ..logging_bootstrap import get_logger, log_llm_preview
import json
from datetime import datetime

logger = get_logger("rna.nodes.fastp")


def create_fastp_agent():
    """åˆ›å»ºFastPèŠ‚ç‚¹çš„React Agent - æ”¯æŒçœŸå®æ‰§è¡Œå’Œæ™ºèƒ½å‚æ•°ä¼˜åŒ–"""
    llm = get_shared_llm()
    
    # ä½¿ç”¨é›†ä¸­ç®¡ç†çš„ç³»ç»Ÿæç¤ºè¯
    system_prompt = FASTP_OPTIMIZATION_PROMPT
    
    # é›†æˆFastPä¸“ç”¨å·¥å…·
    tools = [
        run_nextflow_fastp,      # æ‰§è¡ŒFastPè´¨é‡æ§åˆ¶
        parse_fastp_results      # è§£æFastPç»“æœæ–‡ä»¶
    ]
    
    # åˆ›å»ºæ”¯æŒç»“æ„åŒ–è¾“å‡ºçš„React Agent
    agent = create_react_agent(
        model=llm,
        tools=tools,
        prompt=system_prompt,
        response_format=FastpResponse
    )
    return agent

def append_fastp_optimization_history(state: AgentState, optimization_params: Dict[str, Any], 
                                    suggestions: str, results: Dict[str, Any]) -> None:
    """è¿½åŠ FastPä¼˜åŒ–å†å²è®°å½•ï¼Œä¿æŒæœ€è¿‘5æ¬¡è®°å½•"""
    history_entry = {
        "timestamp": datetime.now().isoformat(),
        "execution_id": f"fastp_run_{len(state.fastp_optimization_history) + 1}",
        "optimization_params": optimization_params or {},
        "optimization_suggestions": suggestions or "",
        "execution_results": results or {}
    }
    
    # è¿½åŠ æ–°è®°å½•
    state.fastp_optimization_history.append(history_entry)
    
    # ä¿æŒæœ€è¿‘5æ¬¡è®°å½•
    if len(state.fastp_optimization_history) > 5:
        state.fastp_optimization_history = state.fastp_optimization_history[-5:]
    
    logger.info(f"[FASTP] å·²è¿½åŠ ä¼˜åŒ–å†å²è®°å½•ï¼Œå½“å‰ä¿å­˜{len(state.fastp_optimization_history)}æ¬¡å†å²")


async def fastp_node(state: AgentState) -> Dict[str, Any]:
    """
    FastPèŠ‚ç‚¹å®ç° - æ‰§è¡Œè´¨é‡æ§åˆ¶å¹¶ç”Ÿæˆä¼˜åŒ–å»ºè®®
    
    åŠŸèƒ½ï¼š
    - æ‰§è¡ŒFastPè´¨é‡æ§åˆ¶
    - åŸºäºAgentæ™ºèƒ½ä¼˜åŒ–å‚æ•°
    - æ›´æ–°çŠ¶æ€ä¿¡æ¯
    - ç”Ÿæˆoptimization_paramsä¾›è·¯ç”±å†³ç­–å™¨ä½¿ç”¨
    """
    logger.info("FastPè´¨æ§èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œ...")
    
    # æ›´æ–°æ‰§è¡Œè¿›åº¦
    completed_steps = state.completed_steps.copy() if state.completed_steps else []
    if "fastp" not in completed_steps:
        completed_steps.append("fastp")
    
    try:
        # ç»Ÿä¸€é€šè¿‡Agentæ‰§è¡ŒFastPï¼Œç”Ÿæˆä¼˜åŒ–å»ºè®®
        logger.info("[FASTP] è°ƒç”¨Agentæ‰§è¡ŒFastPè´¨æ§å’Œä¼˜åŒ–åˆ†æ...")
        agent_response = await _call_fastp_optimization_agent(state)

        # æ›´æ–°æ‰§è¡Œå‚æ•°å’Œä¼˜åŒ–å»ºè®®
        optimized_params = agent_response.fastp_params
        optimization_reasoning = agent_response.fastp_optimization_suggestions
        optimization_params_changes = agent_response.fastp_optimization_params

        # å¤„ç†æ‰§è¡Œç»“æœ
        fastp_results = {
            "success": True,
            "status": "success"
        }
        try:
            if getattr(agent_response, 'fastp_results', None):
                agent_results = agent_response.fastp_results or {}
                fastp_results.update(agent_results)  # ç›´æ¥æ›´æ–°æ‰€æœ‰ç»“æœï¼ŒåŒ…æ‹¬params_file
        except Exception:
            fastp_results["success"] = False
            fastp_results["status"] = "failed"

        # ç”Ÿæˆå“åº”ä¿¡æ¯
        optimization_count = len(optimization_params_changes or {})
        if optimization_count > 0:
            response = (
                f"âœ… FastPè´¨æ§å®Œæˆ\n- è´¨æ§çŠ¶æ€: æˆåŠŸå®Œæˆ\n- ä¼˜åŒ–åˆ†æ: ç”Ÿæˆäº†{optimization_count}ä¸ªä¼˜åŒ–å»ºè®®\n\n"
                f"âš¡ ä¼˜åŒ–è¯¦æƒ…: {optimization_reasoning}"
            )
        else:
            response = (
                "âœ… FastPè´¨æ§å®Œæˆ\n\n"
                "ğŸš€ æ‰§è¡Œè¯¦æƒ…: å·²å®Œæˆè´¨é‡æ§åˆ¶ï¼Œå½“å‰å‚æ•°é…ç½®å·²æ˜¯æœ€ä¼˜"
            )

        logger.info(f"[FASTP] FastPæ‰§è¡Œå®Œæˆï¼Œç”Ÿæˆ{optimization_count}ä¸ªä¼˜åŒ–å‚æ•°")

        # è¿½åŠ ä¼˜åŒ–å†å²è®°å½•
        append_fastp_optimization_history(
            state=state,
            optimization_params=optimization_params_changes,
            suggestions=optimization_reasoning,
            results=fastp_results
        )

        # æ„å»ºæˆåŠŸç»“æœ
        result = {
            "success": True,
            "status": "fastp_completed",
            "current_step": "fastp",
            "completed_steps": completed_steps,
            "response": response,
            "fastp_params": optimized_params,
            "fastp_optimization_suggestions": optimization_reasoning,
            "fastp_optimization_params": optimization_params_changes,
            "fastp_results": fastp_results,
        }



        return result

    except Exception as e:
        logger.error(f"[FASTP] FastPæ‰§è¡Œå¤±è´¥: {str(e)}")
        return {
            "success": False,
            "status": "fastp_failed",
            "response": f"âŒ FastPæ‰§è¡Œå¤±è´¥: {str(e)}",
            "current_step": "fastp",
            "completed_steps": completed_steps,
            "fastp_results": {
                "success": False,
                "status": "failed", 
                "error": str(e)
            }
        }


async def _call_fastp_optimization_agent(state: AgentState) -> FastpResponse:
    """è°ƒç”¨FastPä¼˜åŒ–Agentè¿›è¡Œæ™ºèƒ½å‚æ•°ä¼˜åŒ–"""
    
    # ç»„ç»‡æ•°æ®ä¸Šä¸‹æ–‡ï¼ˆä»…æ•°æ®ï¼Œä¸é‡å¤æµç¨‹ä¸æŒ‡å—ï¼Œéµå¾ªç³»ç»Ÿæç¤ºï¼‰
    sample_info = {
        "sample_groups": state.nextflow_config.get("sample_groups", []),
        # è¡¥å…… paired_endï¼Œç¡®ä¿å·¥å…·æ‹¿åˆ°ä¸ Prepare ä¸€è‡´çš„æµ‹åºç±»å‹
        "paired_end": state.nextflow_config.get("paired_end"),
        # ç»“æœç›®å½•å¯é€‰æä¾›ï¼Œå·¥å…·å†…éƒ¨ä¼šè‡ªåŠ¨å…œåº•
        **({"results_dir": state.results_dir} if state.results_dir else {}),
        # M2: æ·»åŠ  state ä¿¡æ¯ç”¨äºå‚æ•°ç‰ˆæœ¬åŒ–
        "state_info": {
            "results_dir": state.results_dir,
            "results_timestamp": state.results_timestamp
        }
    }

    # æå–èµ„æºé…ç½®ç‰‡æ®µï¼ˆä»… FastPï¼‰
    fastp_resource_config = state.resource_config.get("fastp") if state.resource_config else {}

    user_context = {
        "execution_mode": state.execution_mode,
        "sample_info": sample_info,
        "fastp_resource_config": fastp_resource_config,
        "current_fastp_params": state.fastp_params,
        "optimization_history": state.fastp_optimization_history
    }

    user_prompt = json.dumps(user_context, ensure_ascii=False, indent=2)
    
    # åˆ›å»ºå¹¶è°ƒç”¨Agent
    agent_executor = create_fastp_agent()
    
    # æ„å»ºæ¶ˆæ¯æ ¼å¼
    messages = [
        {"role": "user", "content": user_prompt}
    ]
    
    result = await agent_executor.ainvoke({"messages": messages})
    
    # æå–ç»“æ„åŒ–å“åº”
    structured_response = result.get("structured_response")
    try:
        if structured_response:
            log_llm_preview(logger, "fastp", structured_response)
        else:
            log_llm_preview(logger, "fastp.raw", {"keys": list(result.keys())[:10]})
    except Exception:
        pass
    if not structured_response:
        raise ValueError("Agentè¿”å›çš„ç»“æ„åŒ–å“åº”ä¸ºç©º")
    
    return structured_response
