"""
STARèŠ‚ç‚¹ - ç”¨äºæ‰§è¡ŒSTARæ¯”å¯¹åˆ†æ
"""

from typing import Any, Dict
from langgraph.prebuilt import create_react_agent
from ..state import AgentState, StarResponse
from ..core import get_shared_llm
from ..prompts import STAR_OPTIMIZATION_PROMPT
from ..tools import download_genome_assets, build_star_index, run_nextflow_star, parse_star_metrics, scan_genome_files
import json


def create_star_agent():
    """åˆ›å»ºSTARèŠ‚ç‚¹çš„React Agent"""
    llm = get_shared_llm()

    # ç»‘å®šSTARç›¸å…³å·¥å…·
    tools = [
        scan_genome_files,
        download_genome_assets,
        build_star_index,
        run_nextflow_star,
        parse_star_metrics,
    ]

    # åˆ›å»ºä½¿ç”¨å·¥å…·çš„React Agent
    agent = create_react_agent(
        model=llm,
        tools=tools,
        prompt=STAR_OPTIMIZATION_PROMPT,
        response_format=StarResponse,
    )
    return agent


def star_node(state: AgentState) -> Dict[str, Any]:
    """
    STARèŠ‚ç‚¹å®ç°

    åŠŸèƒ½ï¼š
    - æ‰§è¡ŒSTARæ¯”å¯¹
    - ç”Ÿæˆæ¯”å¯¹ç»Ÿè®¡
    - æ›´æ–°çŠ¶æ€ä¿¡æ¯
    """
    print("\nğŸ¯ STARæ¯”å¯¹èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œ...")

    # æ›´æ–°æ‰§è¡Œè¿›åº¦
    completed_steps = state.completed_steps.copy() if state.completed_steps else []
    if "star" not in completed_steps:
        completed_steps.append("star")

    # è·å–æ‰§è¡Œæ¨¡å¼
    execution_mode = state.execution_mode

    # æ£€æŸ¥FastPç»“æœä¾èµ–ï¼ˆå¼ºåˆ¶ï¼‰
    if not state.fastp_results or not state.fastp_results.get("success"):
        return {
            "status": "star_failed",
            "response": "âŒ STARæ¯”å¯¹å¤±è´¥ï¼šç¼ºå°‘æœ‰æ•ˆçš„FastPè´¨æ§ç»“æœï¼Œè¯·å…ˆå®ŒæˆFastPè´¨é‡æ§åˆ¶",
            "current_step": "star",
            "completed_steps": completed_steps,
        }

    try:
        print(f"âš¡ [AGENT] ä½¿ç”¨STAR Agentè¿›è¡Œæ¯”å¯¹ä¸èµ„æºç®¡ç† (æ¨¡å¼: {execution_mode})")

        if execution_mode == "single":
            # å•æ¬¡æ‰§è¡Œï¼šä»…æ‰§è¡Œæ¯”å¯¹ï¼Œä¸åšå‚æ•°ä¼˜åŒ–
            star_response = _call_star_optimization_agent(state)

            result = {
                "status": "star_completed",
                "response": "âœ… STARæ¯”å¯¹å®Œæˆï¼ˆå•æ¬¡æ‰§è¡Œæ¨¡å¼ï¼‰\n\nğŸš€ **æ‰§è¡Œè¯¦æƒ…**: å·²å®Œæˆæ¯”å¯¹ï¼Œä¿æŒåŸæœ‰å‚æ•°é…ç½®",
                "current_step": "star",
                "completed_steps": completed_steps,
                "star_results": {
                    "status": "success",
                    "summary": "STARæ¯”å¯¹å®Œæˆï¼Œå•æ¬¡æ‰§è¡Œæ¨¡å¼",
                },
            }
            return result

        elif execution_mode == "optimized":
            # ç²¾ç»†ä¼˜åŒ–ï¼šæ‰§è¡Œ+è§£æ+åº”ç”¨ä¼˜åŒ–
            star_response = _call_star_optimization_agent(state)

            result = {
                "status": "star_completed",
                "current_step": "star",
                "completed_steps": completed_steps,
                "star_params": star_response.star_params,
                "star_optimization_suggestions": star_response.star_optimization_suggestions,
                "star_optimization_params": star_response.star_optimization_params,
                "star_results": {
                    "status": "success",
                    "summary": "STARæ¯”å¯¹å®Œæˆï¼Œå·²åº”ç”¨æ™ºèƒ½ä¼˜åŒ–å‚æ•°",
                },
            }

            optimization_count = len(star_response.star_optimization_params or {})
            result["response"] = (
                f"âœ… STARæ¯”å¯¹å®Œæˆå¹¶å·²ä¼˜åŒ–\n- æ¯”å¯¹çŠ¶æ€: æˆåŠŸå®Œæˆ\n- å‚æ•°ä¼˜åŒ–: åº”ç”¨äº†{optimization_count}ä¸ªä¼˜åŒ–å‚æ•°\n\n"
                f"âš¡ **ä¼˜åŒ–è¯¦æƒ…**: {star_response.star_optimization_suggestions}"
            )
            return result

        elif execution_mode == "batch_optimize":
            # æ‰¹æ¬¡ä¼˜åŒ–ï¼šæ‰§è¡Œ+è§£æ+æ”¶é›†ä¼˜åŒ–ï¼Œä¸åº”ç”¨
            star_response = _call_star_optimization_agent(state)

            star_optimization = {
                "optimization_reasoning": star_response.star_optimization_suggestions,
                "suggested_params": star_response.star_optimization_params,
                "current_params": state.star_params.copy(),
                "tool_name": "star",
            }

            batch_optimizations = state.batch_optimizations.copy()
            batch_optimizations["star"] = star_optimization

            result = {
                "status": "star_completed",
                "current_step": "star",
                "completed_steps": completed_steps,
                "batch_optimizations": batch_optimizations,
                "star_optimization_suggestions": star_response.star_optimization_suggestions,
                "star_results": {
                    "status": "success",
                    "summary": "STARæ¯”å¯¹å®Œæˆï¼Œä¼˜åŒ–å»ºè®®å·²æ”¶é›†",
                },
            }

            optimization_count = len(star_response.star_optimization_params or {})
            result["response"] = (
                f"âœ… STARæ¯”å¯¹å®Œæˆ\n- æ¯”å¯¹çŠ¶æ€: æˆåŠŸå®Œæˆ\n- ä¼˜åŒ–æ”¶é›†: {optimization_count}ä¸ªå‚æ•°ä¼˜åŒ–å»ºè®®å·²æ”¶é›†\n\n"
                f"ğŸ“¦ **æ”¶é›†çš„ä¼˜åŒ–å»ºè®®**: {star_response.star_optimization_suggestions}"
            )
            return result

        else:
            # æœªçŸ¥æ¨¡å¼ï¼šæŒ‰ single å¤„ç†
            print(f"â„¹ï¸ æœªçŸ¥æ‰§è¡Œæ¨¡å¼ '{execution_mode}'ï¼ŒæŒ‰ single å¤„ç†")
            star_response = _call_star_optimization_agent(state)
            return {
                "status": "star_completed",
                "response": "âœ… STARæ¯”å¯¹å®Œæˆï¼ˆæŒ‰singleå¤„ç†ï¼‰\n\nğŸš€ **æ‰§è¡Œè¯¦æƒ…**: å·²å®Œæˆæ¯”å¯¹ï¼Œä¿æŒåŸæœ‰å‚æ•°é…ç½®",
                "current_step": "star",
                "completed_steps": completed_steps,
                "star_results": {"status": "success", "summary": "STARæ¯”å¯¹å®Œæˆï¼ˆsingleæ¨¡å¼ï¼‰"},
            }

    except Exception as e:
        print(f"âŒ STARèŠ‚ç‚¹æ‰§è¡Œå¤±è´¥: {str(e)}")
        return {
            "status": "star_failed",
            "response": f"âŒ STARæ¯”å¯¹æ‰§è¡Œå¤±è´¥: {str(e)}",
            "current_step": "star",
            "completed_steps": completed_steps,
            "star_results": {"status": "failed", "error": str(e)},
        }


def _call_star_optimization_agent(state: AgentState) -> StarResponse:
    """è°ƒç”¨STAR Agentï¼Œæ ¹æ®æ‰§è¡Œæ¨¡å¼åŒºåˆ†è¡Œä¸ºï¼Œç»Ÿä¸€è¿”å›ç»“æ„åŒ–å“åº”"""
    # ç»„ç»‡ä¸Šä¸‹æ–‡ï¼ˆä»…æ•°æ®ï¼‰
    user_context = {
        "execution_mode": state.execution_mode,
        "fastp_results": state.fastp_results,
        "nextflow_config": state.nextflow_config,
        "current_star_params": state.star_params,
        "optimization_history": {
            "star": state.star_optimization_params,
            "fastp": state.fastp_optimization_params,
        },
    }

    # æ¨¡å¼æŒ‡ä»¤
    mode = (state.execution_mode or "single").lower()
    if mode == "single":
        mode_instructions = (
            "æœ¬æ¬¡æ‰§è¡Œæ¨¡å¼ä¸º singleï¼ˆå•æ¬¡æ‰§è¡Œï¼‰ã€‚\n"
            "- ä»…æ‰§è¡Œ STAR æ¯”å¯¹ä¸å¿…è¦çš„èµ„æºå‡†å¤‡ï¼ˆä¸‹è½½/ç´¢å¼•ï¼‰ï¼Œä¸è¿›è¡Œä»»ä½•å‚æ•°ä¼˜åŒ–ã€‚\n"
            "- å¿…é¡»åŸºäº FastP ä¿®å‰ªåçš„ FASTQ è¿›è¡Œæ¯”å¯¹ã€‚\n"
            "- ä¿æŒ current_star_params åŸæ ·è¿”å›ï¼Œstar_optimization_params å¿…é¡»ä¸ºç©ºå¯¹è±¡ã€‚\n"
            "- å¯è°ƒç”¨ parse_star_metrics æå–å…³é”®æŒ‡æ ‡ä»¥å½¢æˆæ‘˜è¦ã€‚\n"
            "- ä»éœ€è¿”å› StarResponse ç»“æ„åŒ–ç»“æœã€‚\n"
        )
    elif mode == "batch_optimize":
        mode_instructions = (
            "æœ¬æ¬¡æ‰§è¡Œæ¨¡å¼ä¸º batch_optimizeï¼ˆæ‰¹æ¬¡ä¼˜åŒ–ï¼‰ã€‚\n"
            "- æ‰§è¡Œ STAR å¹¶è§£æç»“æœï¼Œç”Ÿæˆä¼˜åŒ–å»ºè®®ï¼Œä½†ä¸è¦åœ¨å½“å‰èŠ‚ç‚¹åº”ç”¨è¿™äº›å‚æ•°ã€‚\n"
            "- star_params è¯·ç»™å‡ºâ€œå»ºè®®åçš„å®Œæ•´å‚æ•°å­—å…¸â€ï¼Œstar_optimization_params ä»…åŒ…å«æ”¹åŠ¨çš„é”®å€¼å¯¹ã€‚\n"
        )
    else:  # optimized
        mode_instructions = (
            "æœ¬æ¬¡æ‰§è¡Œæ¨¡å¼ä¸º optimizedï¼ˆç²¾ç»†ä¼˜åŒ–ï¼‰ã€‚\n"
            "- æ‰§è¡Œ STARã€è§£æç»“æœå¹¶ç”Ÿæˆä¼˜åŒ–å»ºè®®ã€‚\n"
            "- star_params è¯·è¿”å›â€œåº”ç”¨ä¼˜åŒ–åçš„å®Œæ•´å‚æ•°å­—å…¸â€ï¼Œstar_optimization_params ä»…åŒ…å«æ”¹åŠ¨é¡¹ã€‚\n"
        )

    # ç»„è£…ç”¨æˆ·æ¶ˆæ¯
    user_prompt = (
        "è¯·ä¾æ®ç³»ç»Ÿæç¤ºä¸­çš„æ ‡å‡†æµç¨‹ä¸æŒ‡å¯¼åŸåˆ™æ‰§è¡Œæœ¬æ¬¡ä»»åŠ¡ã€‚\n\n"
        + mode_instructions
        + "ä»¥ä¸‹ä¸ºæœ¬æ¬¡ä»»åŠ¡çš„ä¸Šä¸‹æ–‡æ•°æ®ï¼ˆJSONï¼‰ï¼š\n\n"
        + json.dumps(user_context, ensure_ascii=False, indent=2)
        + "\n\nè¯·åŸºäºä¸Šè¿°æ•°æ®å®Œæˆå¿…è¦çš„å·¥å…·è°ƒç”¨ï¼Œå¹¶æŒ‰ç³»ç»Ÿæç¤ºè¦æ±‚è¿”å›ç»“æ„åŒ–ç»“æœï¼ˆStarResponseï¼‰ã€‚"
    )

    # è°ƒç”¨Agent
    agent = create_star_agent()
    messages = [{"role": "user", "content": user_prompt}]
    result = agent.invoke({"messages": messages})

    # æå–ç»“æ„åŒ–å“åº”
    structured = result.get("structured_response") if isinstance(result, dict) else None
    if structured and isinstance(structured, StarResponse):
        return structured

    # å…¼å®¹ä¸åŒè¿”å›å½¢æ€
    if hasattr(result, "content") and isinstance(result.content, StarResponse):
        return result.content
    if hasattr(result, "content") and getattr(result.content, "star_params", None) is not None:
        return result.content

    # å…œåº•ï¼šä¿æŒå½“å‰å‚æ•°
    return StarResponse(
        star_params=state.star_params,
        star_optimization_suggestions=(
            "STARæ‰§è¡Œå®Œæˆï¼Œå•æ¬¡æ‰§è¡Œä¸åšä¼˜åŒ–" if mode == "single" else "STARæ‰§è¡Œå®Œæˆï¼Œä½†æœªè¿”å›æœ‰æ•ˆä¼˜åŒ–å»ºè®®"
        ),
        star_optimization_params={},
    )
