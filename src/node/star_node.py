"""
STARèŠ‚ç‚¹ - ç”¨äºæ‰§è¡ŒSTARæ¯”å¯¹åˆ†æ
"""

from typing import Any, Dict
from langgraph.prebuilt import create_react_agent
from ..state import AgentState, StarResponse
from ..core import get_shared_llm


def create_star_agent():
    """åˆ›å»ºSTARèŠ‚ç‚¹çš„React Agent"""
    llm = get_shared_llm()
    
    system_prompt = """ä½ æ˜¯RNA-seqåˆ†ææµæ°´çº¿ä¸­çš„STARæ¯”å¯¹ä¸“å®¶ã€‚

ä½ çš„ä»»åŠ¡ï¼š
1. åˆ†æFastPè´¨æ§åçš„æ•°æ®çŠ¶æ€
2. æ‰§è¡ŒSTARåºåˆ—æ¯”å¯¹å¤„ç†
3. ç”Ÿæˆæ¯”å¯¹ç»Ÿè®¡å’Œè´¨é‡æŠ¥å‘Š
4. è¿”å›ç»“æ„åŒ–çš„æ‰§è¡Œç»“æœ

è¯·æ ¹æ®æä¾›çš„çŠ¶æ€ä¿¡æ¯ï¼Œæ‰§è¡ŒSTARæ¯”å¯¹å¤„ç†ï¼Œå¹¶è¿”å›è¯¦ç»†çš„æ‰§è¡Œç»“æœã€‚
ç›®å‰è¿™æ˜¯å ä½å®ç°ï¼Œè¯·è¿”å›æ¨¡æ‹Ÿçš„æˆåŠŸç»“æœã€‚

è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
- status: "success" è¡¨ç¤ºæˆåŠŸ
- summary: ç®€è¦çš„æ‰§è¡Œæ€»ç»“ï¼ŒåŒ…å«æ¯”å¯¹ç»Ÿè®¡ä¿¡æ¯
- response: è¯¦ç»†çš„å“åº”æ¶ˆæ¯
"""
    
    # åˆ›å»ºä¸ä½¿ç”¨å·¥å…·çš„React Agent
    agent = create_react_agent(
        model=llm,
        tools=[],  # æš‚ä¸ä½¿ç”¨å·¥å…·
        prompt=system_prompt,
        response_format=StarResponse
    )
    return agent


def star_node(state: AgentState) -> Dict[str, Any]:
    """
    STARèŠ‚ç‚¹å®ç°
    
    åŠŸèƒ½ï¼š
    - æ‰§è¡ŒSTARæ¯”å¯¹
    - ç”Ÿæˆæ¯”å¯¹ç»Ÿè®¡
    - æ›´æ–°çŠ¶æ€ä¿¡æ¯
    """
    print("\nğŸ¯ STARæ¯”å¯¹èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œ...")
    
    # æ›´æ–°æ‰§è¡Œè¿›åº¦
    completed_steps = state.completed_steps.copy() if state.completed_steps else []
    if "star" not in completed_steps:
        completed_steps.append("star")
    
    # è·å–å‰ä¸€æ­¥çš„ä¿¡æ¯
    sample_count = len(state.nextflow_config.get('sample_groups', []))
    species = state.nextflow_config.get('species', 'human')
    execution_mode = state.execution_mode
    
    # åŸºç¡€æ‰§è¡Œç»“æœ
    result = {
        "status": "star_completed",
        "response": f"âœ… STARæ¯”å¯¹å®Œæˆ\n- æ¯”å¯¹æ ·æœ¬: {sample_count}ä¸ª\n- ç‰©ç§: {species}\n- æ¯”å¯¹ç‡: 88.5%\n- å”¯ä¸€æ¯”å¯¹: 82.3%",
        "current_step": "star",
        "completed_steps": completed_steps,
        "star_results": {
            "status": "success",
            "summary": f"STARæˆåŠŸæ¯”å¯¹{sample_count}ä¸ªæ ·æœ¬ï¼Œå¹³å‡æ¯”å¯¹ç‡88.5%"
        }
    }
    
    # æ ¹æ®æ‰§è¡Œæ¨¡å¼å¤„ç†ä¼˜åŒ–é€»è¾‘
    if execution_mode == "single":
        # å•æ¬¡æ‰§è¡Œæ¨¡å¼ï¼šä¸ç”Ÿæˆä»»ä½•ä¼˜åŒ–å‚æ•°
        print("ğŸš€ [SINGLE] å•æ¬¡æ‰§è¡Œæ¨¡å¼ï¼Œç›´æ¥å®Œæˆ")
        result["response"] += "\n\nğŸš€ **å•æ¬¡æ‰§è¡Œ**: ä»»åŠ¡å®Œæˆï¼Œæ— ä¼˜åŒ–å¤„ç†"
        
    elif execution_mode == "optimized":
        # ç²¾ç»†ä¼˜åŒ–æ¨¡å¼ï¼šç«‹å³åº”ç”¨ä¼˜åŒ–å‚æ•°
        print("âš¡ [OPTIMIZED] ç²¾ç»†ä¼˜åŒ–æ¨¡å¼ï¼Œç«‹å³åº”ç”¨ä¼˜åŒ–...")
        
        # ç¡¬ç¼–ç æ¨¡æ‹Ÿä¼˜åŒ–å‚æ•°
        optimization_suggestions = {
            "--runThreadN": 16,
            "--outFilterMultimapNmax": 20,
            "--outFilterMismatchNmax": 2,
            "--alignIntronMax": 1000000
        }
        optimization_reasoning = "æ¯”å¯¹ç‡88.5%ç•¥ä½ï¼Œå·²åº”ç”¨å¤šé‡æ¯”å¯¹å’Œçº¿ç¨‹æ•°ä¼˜åŒ–"
        
        # ç«‹å³æ›´æ–°æ‰§è¡Œå‚æ•°
        optimized_params = {**state.star_params, **optimization_suggestions}
        result["star_params"] = optimized_params
        result["star_optimization_suggestions"] = optimization_reasoning
        result["response"] += f"\n\nâš¡ **ç«‹å³ä¼˜åŒ–**: {optimization_reasoning}"
        
        print(f"âœ… [OPTIMIZED] STARä¼˜åŒ–å‚æ•°å·²åº”ç”¨: {len(optimization_suggestions)}ä¸ªå‚æ•°")
        
    elif execution_mode == "batch_optimize":
        # æ‰¹æ¬¡ä¼˜åŒ–æ¨¡å¼ï¼šæ”¶é›†ä¼˜åŒ–å‚æ•°
        print("ğŸ“¦ [BATCH] STARæ‰¹æ¬¡ä¼˜åŒ–æ¨¡å¼ï¼Œæ”¶é›†ä¼˜åŒ–å‚æ•°...")
        
        # ç¡¬ç¼–ç æ¨¡æ‹ŸSTARä¼˜åŒ–å‚æ•°
        star_optimization = {
            "optimization_reasoning": "æ¯”å¯¹ç‡88.5%ç•¥ä½äºæœ€ä½³æ°´å¹³ï¼Œå»ºè®®è°ƒæ•´å¤šé‡æ¯”å¯¹å‚æ•°å’Œçº¿ç¨‹æ•°ä»¥æå‡æ€§èƒ½",
            "suggested_params": {
                "--runThreadN": 16,
                "--outFilterMultimapNmax": 20,
                "--outFilterMismatchNmax": 2,
                "--alignIntronMax": 1000000
            },
            "current_params": state.star_params.copy(),
            "tool_name": "star"
        }
        
        # å°†ä¼˜åŒ–å‚æ•°æ·»åŠ åˆ°æ‰¹æ¬¡æ”¶é›†å™¨ï¼ˆç»§æ‰¿ä¹‹å‰çš„æ”¶é›†ç»“æœï¼‰
        batch_optimizations = state.batch_optimizations.copy()
        batch_optimizations["star"] = star_optimization
        
        result["batch_optimizations"] = batch_optimizations
        # ä¹Ÿè®°å½•ä¼˜åŒ–ç†ç”±ï¼Œä¾¿äºåœ¨ç¡®è®¤é¡µå±•ç¤º
        result["star_optimization_suggestions"] = star_optimization.get("optimization_reasoning", "")
        result["response"] += "\n\nğŸ“¦ **STARä¼˜åŒ–å‚æ•°å·²æ”¶é›†**: æ¯”å¯¹ç‡åä½ï¼Œå»ºè®®è°ƒæ•´å¤šé‡æ¯”å¯¹å‚æ•°"
        
        print(f"âœ… [BATCH] STARä¼˜åŒ–å‚æ•°æ”¶é›†å®Œæˆ: {len(star_optimization['suggested_params'])}ä¸ªå‚æ•°")
    
    return result
