from typing import Dict, Any, List
import asyncio
from ..state import AgentState, DetectResponse
from langgraph.prebuilt import create_react_agent
from langchain.tools import Tool
from ..tools import (
    scan_fastq_files,
    scan_system_resources,
    scan_genome_files,
    check_fastp_availability,
    check_star_availability,
    check_featurecounts_availability
)
from ..core import get_shared_llm


async def _execute_task_group(group_tasks: List[str], group_description: str) -> Dict[str, Any]:
    """æ‰§è¡Œå•ä¸ªä»»åŠ¡ç»„ä¸­çš„æ‰€æœ‰ä»»åŠ¡ï¼ˆç»„å†…ä¸²è¡Œæ‰§è¡Œï¼‰"""
    print(f"ğŸ”„ å¼€å§‹æ‰§è¡Œ{group_description}: {group_tasks}")
    
    # ä»»åŠ¡åç§°åˆ°å‡½æ•°çš„æ˜ å°„
    task_mapping = {
        "analyze_fastq_data": lambda: scan_fastq_files(mode="detect", depth="detailed"),
        "assess_system_readiness": lambda: scan_system_resources(mode="detect"),
        "verify_genome_setup": lambda: scan_genome_files(mode="detect"),
        "check_fastp_availability": check_fastp_availability,
        "check_star_availability": check_star_availability,
        "check_featurecounts_availability": check_featurecounts_availability
    }
    
    group_results = {}
    group_errors = []
    
    # ç»„å†…ä¸²è¡Œæ‰§è¡Œä»»åŠ¡
    for task_name in group_tasks:
        try:
            if task_name in task_mapping:
                print(f"  ğŸ¯ æ‰§è¡Œä»»åŠ¡: {task_name}")
                result = task_mapping[task_name]()
                group_results[task_name] = result
                print(f"  âœ… {task_name} æ‰§è¡Œå®Œæˆ")
            else:
                error_msg = f"æœªçŸ¥ä»»åŠ¡: {task_name}"
                group_errors.append(error_msg)
                print(f"  âŒ {error_msg}")
        except Exception as e:
            error_msg = f"{task_name} æ‰§è¡Œå¤±è´¥: {str(e)}"
            group_errors.append(error_msg)
            print(f"  âŒ {error_msg}")
    
    print(f"âœ… {group_description}æ‰§è¡Œå®Œæˆï¼ŒæˆåŠŸ{len(group_results)}ä¸ªï¼Œå¤±è´¥{len(group_errors)}ä¸ª")
    
    return {
        "group_description": group_description,
        "group_tasks": group_tasks,
        "results": group_results,
        "errors": group_errors,
        "success_count": len(group_results),
        "total_count": len(group_tasks)
    }


def create_detection_agent():
    """åˆ›å»ºæ£€æµ‹æ‰§è¡ŒAgentï¼ˆä¿ç•™ç”¨äºå‘åå…¼å®¹ï¼‰"""
    llm = get_shared_llm()
    
    # ç›´æ¥å®šä¹‰æ£€æµ‹å·¥å…·åˆ—è¡¨
    tools = [
        Tool(
            name="analyze_fastq_data",
            func=lambda query="": scan_fastq_files(mode="detect", depth="detailed"),
            description="æ‰«æå’Œåˆ†æFASTQæ–‡ä»¶ã€‚æ”¶é›†é¡¹ç›®ä¸­æ‰€æœ‰FASTQæ–‡ä»¶çš„ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ–‡ä»¶å¤§å°ã€æ ·æœ¬é…å¯¹å…³ç³»ã€æµ‹åºç±»å‹ç­‰ã€‚"
        ),
        Tool(
            name="assess_system_readiness", 
            func=lambda query="": scan_system_resources(mode="detect"),
            description="æ£€æµ‹ç³»ç»Ÿç¡¬ä»¶èµ„æºã€‚è¯„ä¼°CPUæ ¸å¿ƒæ•°ã€å†…å­˜å®¹é‡ã€ç£ç›˜ç©ºé—´ã€ç³»ç»Ÿè´Ÿè½½ç­‰ç¡¬ä»¶ä¿¡æ¯ã€‚"
        ),
        Tool(
            name="verify_genome_setup",
            func=lambda query="": scan_genome_files(mode="detect"), 
            description="éªŒè¯åŸºå› ç»„æ–‡ä»¶é…ç½®ã€‚æ£€æŸ¥å·²é…ç½®åŸºå› ç»„çš„FASTAæ–‡ä»¶ã€GTFæ–‡ä»¶ã€STARç´¢å¼•æ–‡ä»¶çš„å­˜åœ¨æ€§å’Œå®Œæ•´æ€§ã€‚"
        ),
        Tool(
            name="check_fastp_availability",
            func=check_fastp_availability,
            description="æ£€æµ‹fastpè´¨æ§å·¥å…·çš„å¯ç”¨æ€§ã€‚åœ¨micromambaç¯å¢ƒä¸­æµ‹è¯•fastpå‘½ä»¤æ˜¯å¦å¯æ‰§è¡Œã€‚"
        ),
        Tool(
            name="check_star_availability", 
            func=check_star_availability,
            description="æ£€æµ‹STARæ¯”å¯¹å·¥å…·çš„å¯ç”¨æ€§ã€‚åœ¨micromambaç¯å¢ƒä¸­æµ‹è¯•STARå‘½ä»¤æ˜¯å¦å¯æ‰§è¡Œã€‚"
        ),
        Tool(
            name="check_featurecounts_availability",
            func=check_featurecounts_availability,
            description="æ£€æµ‹featureCountså®šé‡å·¥å…·çš„å¯ç”¨æ€§ã€‚åœ¨micromambaç¯å¢ƒä¸­æµ‹è¯•featureCountså·¥å…·æ˜¯å¦å¯æ‰§è¡Œã€‚"
        )
    ]
    
    system_prompt = """ä½ æ˜¯æ£€æµ‹æ‰§è¡Œä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®è®¡åˆ’åˆ—è¡¨ï¼Œæ™ºèƒ½æ‰§è¡Œæ£€æµ‹ä»»åŠ¡å¹¶æ”¶é›†ç»“æœã€‚

æ‰§è¡ŒåŸåˆ™ï¼š
1. æŒ‰è®¡åˆ’åˆ—è¡¨ä¸­çš„ä»»åŠ¡åç§°ï¼Œä¾æ¬¡è°ƒç”¨å¯¹åº”çš„æ£€æµ‹å·¥å…·
2. å¯¹äºæ¯ä¸ªä»»åŠ¡ï¼Œåªè°ƒç”¨ä¸€æ¬¡ç›¸åº”çš„å·¥å…·
3. å¦‚æœæ£€æµ‹å¤±è´¥ï¼Œè®°å½•é”™è¯¯ä½†ç»§ç»­æ‰§è¡Œå…¶ä»–ä»»åŠ¡
4. æ”¶é›†æ‰€æœ‰æ£€æµ‹ç»“æœï¼Œæ•´åˆæˆç»Ÿä¸€çš„æ•°æ®ç»“æ„

è¿”å›æ ¼å¼ç¤ºä¾‹ï¼š
{
  "query_results": {"æ£€æµ‹ç»“æœæŒ‰ä»»åŠ¡æ•´ç†": "å·¥å…·å·²ä¼˜åŒ–è¾“å‡ºæ ¼å¼"},
  "query_summary": "æ£€æµ‹å®Œæˆï¼šåŸºå› ç»„hg19å¯ç”¨ï¼Œå·¥å…·å°±ç»ªï¼Œå‘ç°6ä¸ªFASTQæ–‡ä»¶"
}

å¯ç”¨çš„æ£€æµ‹å·¥å…·ï¼š
- analyze_fastq_data: åˆ†æFASTQæ–‡ä»¶
- assess_system_readiness: æ£€æµ‹ç³»ç»Ÿèµ„æº
- verify_genome_setup: éªŒè¯åŸºå› ç»„é…ç½®
- check_fastp_availability: æ£€æµ‹fastpå·¥å…·
- check_star_availability: æ£€æµ‹STARå·¥å…·
- check_featurecounts_availability: æ£€æµ‹featureCountså·¥å…·

è¯·æŒ‰ç…§è®¡åˆ’åˆ—è¡¨æ‰§è¡Œæ£€æµ‹ï¼Œå¹¶è¿”å›JSONæ ¼å¼çš„ç»“æœã€‚"""
    
    agent = create_react_agent(
        model=llm,
        tools=tools,
        prompt=system_prompt,
        response_format=DetectResponse
    )
    return agent


async def detect_node(state: AgentState) -> Dict[str, Any]:
    """DetectèŠ‚ç‚¹ - å¹¶è¡Œæ‰§è¡Œä»»åŠ¡ç»„æ£€æµ‹"""
    
    # è·å–ä»»åŠ¡ç»„ä¿¡æ¯ï¼ˆplanç°åœ¨ç›´æ¥æ˜¯List[List[str]]æ ¼å¼ï¼‰
    task_groups = getattr(state, 'plan', [])
    group_descriptions = getattr(state, 'group_descriptions', [])
    execution_strategy = getattr(state, 'execution_strategy', 'parallel')
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ä»»åŠ¡éœ€è¦æ‰§è¡Œ
    if not task_groups or not any(group for group in task_groups):
        return {
            "query_summary": "æ²¡æœ‰æ£€æµ‹ä»»åŠ¡éœ€è¦æ‰§è¡Œ",
            "status": "prepare",
            "query_results": {}
        }
        
    # ç¡®ä¿æœ‰å¯¹åº”çš„ç»„æè¿°
    if len(group_descriptions) < len(task_groups):
        group_descriptions.extend([f"ä»»åŠ¡ç»„{i+1}" for i in range(len(group_descriptions), len(task_groups))])
    
    print(f"ğŸ” DetectèŠ‚ç‚¹å¼€å§‹å¹¶è¡Œæ‰§è¡Œ {len(task_groups)} ä¸ªä»»åŠ¡ç»„")
    print(f"ğŸ“‹ æ‰§è¡Œç­–ç•¥: {execution_strategy}")
    
    try:
        if execution_strategy == "parallel" and len(task_groups) > 1:
            # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰ä»»åŠ¡ç»„
            print(f"ğŸš€ å¯åŠ¨ {len(task_groups)} ä¸ªä»»åŠ¡ç»„çš„å¹¶è¡Œæ‰§è¡Œ")
            
            # åˆ›å»ºå¹¶å‘ä»»åŠ¡
            group_tasks = []
            for i, (group_tasks_list, group_desc) in enumerate(zip(task_groups, group_descriptions)):
                group_tasks.append(_execute_task_group(group_tasks_list, f"{group_desc}(ç»„{i+1})"))
            
            # ä½¿ç”¨asyncio.gatherå¹¶è¡Œæ‰§è¡Œ
            group_results = await asyncio.gather(*group_tasks, return_exceptions=True)
            
        else:
            # é¡ºåºæ‰§è¡Œä»»åŠ¡ç»„
            print(f"ğŸ”„ é¡ºåºæ‰§è¡Œ {len(task_groups)} ä¸ªä»»åŠ¡ç»„")
            group_results = []
            for i, (group_tasks_list, group_desc) in enumerate(zip(task_groups, group_descriptions)):
                result = await _execute_task_group(group_tasks_list, f"{group_desc}(ç»„{i+1})")
                group_results.append(result)
        
        # èšåˆæ‰€æœ‰ç»“æœ
        print(f"ğŸ“Š èšåˆæ£€æµ‹ç»“æœ")
        all_query_results = {}
        all_errors = []
        total_success = 0
        total_tasks = 0
        
        for result in group_results:
            if isinstance(result, Exception):
                error_msg = f"ä»»åŠ¡ç»„æ‰§è¡Œå¼‚å¸¸: {str(result)}"
                all_errors.append(error_msg)
                print(f"âŒ {error_msg}")
                continue
            
            # ç¡®ä¿resultæ˜¯å­—å…¸ç±»å‹
            if not isinstance(result, dict):
                continue
                
            # åˆå¹¶ä»»åŠ¡ç»“æœ
            if 'results' in result:
                all_query_results.update(result['results'])
                total_success += result.get('success_count', 0)
                total_tasks += result.get('total_count', 0)
                
            # æ”¶é›†é”™è¯¯
            if 'errors' in result:
                all_errors.extend(result['errors'])
        
        # ç”Ÿæˆæ‰§è¡Œæ€»ç»“
        summary_parts = []
        summary_parts.append(f"å¹¶è¡Œæ£€æµ‹å®Œæˆ")
        summary_parts.append(f"æˆåŠŸæ‰§è¡Œ {total_success}/{total_tasks} ä¸ªä»»åŠ¡")
        
        if all_errors:
            summary_parts.append(f"å‘ç° {len(all_errors)} ä¸ªé”™è¯¯")
        
        query_summary = "ï¼Œ".join(summary_parts)
        
        print(f"âœ… æ£€æµ‹èŠ‚ç‚¹æ‰§è¡Œå®Œæˆ: {query_summary}")
        
        return {
            "query_summary": query_summary,
            "status": "prepare", 
            "query_results": all_query_results,
            "execution_errors": all_errors if all_errors else None,
            "execution_stats": {
                "total_groups": len(task_groups),
                "total_tasks": total_tasks,
                "successful_tasks": total_success,
                "failed_tasks": total_tasks - total_success,
                "execution_strategy": execution_strategy
            }
        }
        
    except Exception as e:
        print(f"âŒ å¹¶è¡Œæ£€æµ‹æ‰§è¡Œå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        
        return {
            "query_summary": f"å¹¶è¡Œæ£€æµ‹å¤±è´¥: {str(e)}",
            "status": "error",
            "query_results": {},
            "execution_errors": [str(e)]
        }