"""
FastP Agent - RNA-seqè´¨é‡æ§åˆ¶å’Œé¢„å¤„ç†Agent
æ”¯æŒæ™ºèƒ½é…ç½®ã€ç»“æœåˆ†æå’Œå‚æ•°ä¼˜åŒ–
"""

import json
import subprocess
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field

from langchain_core.tools import tool
from langchain_core.messages import HumanMessage

# å¯¼å…¥é¡¹ç›®é…ç½®
from ..config import get_tools_config
from ..core import LLMManager


@dataclass
class FastpConfig:
    """Fastpé…ç½®å‚æ•°ç±»"""
    
    # åŸºæœ¬å‚æ•°
    input_files: List[str]  # è¾“å…¥FASTQæ–‡ä»¶åˆ—è¡¨
    output_dir: str  # è¾“å‡ºç›®å½•
    sample_name: str  # æ ·æœ¬åç§°
    
    # fastpå‚æ•°
    adapter_trimming: bool = True  # è‡ªåŠ¨adapter trimming
    quality_filtering: bool = True  # è´¨é‡è¿‡æ»¤
    length_filtering: bool = True  # é•¿åº¦è¿‡æ»¤
    
    # è´¨é‡å‚æ•°
    qualified_quality_phred: int = 20  # è´¨é‡é˜ˆå€¼
    unqualified_percent_limit: int = 40  # ä½è´¨é‡baseæ¯”ä¾‹é™åˆ¶
    n_base_limit: int = 5  # Nç¢±åŸºæ•°é‡é™åˆ¶
    
    # é•¿åº¦å‚æ•°
    length_required: int = 15  # æœ€çŸ­é•¿åº¦è¦æ±‚
    
    # è¾“å‡ºå‚æ•°
    html_report: bool = True  # ç”ŸæˆHTMLæŠ¥å‘Š
    json_report: bool = True  # ç”ŸæˆJSONæŠ¥å‘Š
    
    fastp_cpus: Optional[int] = None  # è‹¥é€šè¿‡ Nextflow è¿è¡Œï¼Œä½œä¸º process.cpus ä¼ å…¥

    # é¢å¤– fastp é«˜çº§å‚æ•°ï¼ˆæŒ‰éœ€ä¼ é€’ï¼‰
    # è¾“å…¥è´¨é‡ç¼–ç ä¸è¯»å–æ§åˆ¶
    phred64: bool = False                 # -6/--phred64 è¾“å…¥ä¸ºphred64è´¨é‡
    reads_to_process: Optional[int] = None  # --reads_to_process ä»…å¤„ç†å‰Næ¡reads
    fix_mgi_id: bool = False              # --fix_mgi_id ä¿®å¤MGIæµ‹åºID

    # PE adapter è‡ªåŠ¨æ£€æµ‹
    detect_adapter_for_pe: Optional[bool] = None  # è‹¥ä¸ºNoneæŒ‰è‡ªåŠ¨é€»è¾‘ï¼›æ˜¾å¼True/Falseå¯è¦†ç›–

    # å‰åç«¯å®šé•¿ä¿®å‰ªä¸æœ€å¤§é•¿åº¦
    trim_front1: Optional[int] = None     # -f/--trim_front1
    trim_tail1: Optional[int] = None      # -t/--trim_tail1
    max_len1: Optional[int] = None        # -b/--max_len1
    trim_front2: Optional[int] = None     # -F/--trim_front2
    trim_tail2: Optional[int] = None      # -T/--trim_tail2
    max_len2: Optional[int] = None        # -B/--max_len2

    # polyG / polyX ä¿®å‰ª
    trim_poly_g: Optional[bool] = None    # -g/--trim_poly_gï¼ˆIllumina NextSeq/NovaSeqå¸¸è§ï¼‰
    poly_g_min_len: Optional[int] = None  # --poly_g_min_len
    disable_trim_poly_g: Optional[bool] = None  # -G/--disable_trim_poly_g
    trim_poly_x: Optional[bool] = None    # -x/--trim_poly_x
    poly_x_min_len: Optional[int] = None  # --poly_x_min_len

    # æ»‘çª—åˆ‡é™¤ä¸é—¨é™
    cut_front: Optional[int] = None       # -5/--cut_front
    cut_tail: Optional[int] = None        # -3/--cut_tail
    cut_right: Optional[int] = None       # -r/--cut_right
    cut_window_size: Optional[int] = None # -W/--cut_window_size
    cut_mean_quality: Optional[int] = None# -M/--cut_mean_quality
    cut_front_window_size: Optional[int] = None
    cut_front_mean_quality: Optional[int] = None
    cut_tail_window_size: Optional[int] = None
    cut_tail_mean_quality: Optional[int] = None
    cut_right_window_size: Optional[int] = None
    cut_right_mean_quality: Optional[int] = None

    # è´¨é‡/é•¿åº¦è¿‡æ»¤ç»†åŒ–
    average_qual: Optional[int] = None    # -e/--average_qual
    disable_length_filtering: Optional[bool] = None  # -L/--disable_length_filteringï¼ˆä¸ length_filtering ç›¸åï¼‰
    length_limit: Optional[int] = None    # --length_limit
    low_complexity_filter: Optional[bool] = None  # -y/--low_complexity_filter
    complexity_threshold: Optional[int] = None    # -Y/--complexity_threshold

    # PE é‡å æ ¡æ­£ä¸æ£€æµ‹
    correction: Optional[bool] = None     # -c/--correctionï¼ˆä»…PEï¼‰
    overlap_len_require: Optional[int] = None
    overlap_diff_limit: Optional[int] = None
    overlap_diff_percent_limit: Optional[int] = None

    # è¿‡è¡¨è¾¾åºåˆ—åˆ†æ
    overrepresentation_sampling: Optional[int] = None  # -P/--overrepresentation_sampling


@dataclass
class FastpResult:
    """Fastpæ‰§è¡Œç»“æœç±»"""
    
    # æ‰§è¡ŒçŠ¶æ€
    success: bool
    exit_code: int
    error_message: str = ""
    
    # è¾“å‡ºæ–‡ä»¶
    output_files: List[str] = field(default_factory=list)
    html_report: str = ""
    json_report: str = ""
    
    # åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
    total_reads_before: int = 0
    total_reads_after: int = 0
    total_bases_before: int = 0
    total_bases_after: int = 0
    q20_bases_before: int = 0
    q20_bases_after: int = 0
    q30_bases_before: int = 0
    q30_bases_after: int = 0
    
    # æµ‹åºä¿¡æ¯
    sequencing_type: str = ""  # single endæˆ–paired end
    read_length_before: float = 0  # å¹³å‡é•¿åº¦
    read_length_after: float = 0
    
    # GCå«é‡
    gc_content_before: float = 0.0
    gc_content_after: float = 0.0
    
    # è¿‡æ»¤ç»Ÿè®¡
    passed_filter_reads: int = 0
    low_quality_reads: int = 0
    too_many_n_reads: int = 0
    too_short_reads: int = 0
    too_long_reads: int = 0
    
    # æ¥å¤´ä¿¡æ¯
    adapter_trimmed_reads: int = 0
    adapter_trimmed_bases: int = 0
    detected_adapters: List[str] = field(default_factory=list)
    
    # é‡å¤ç‡
    duplication_rate: float = 0.0
    
    # è¿‡åº¦è¡¨è¾¾åºåˆ—
    overrepresented_sequences: int = 0
    top_overrepresented: List[Dict[str, Any]] = field(default_factory=list)
    
    # è´¨é‡è¯„ä¼°
    mean_quality_before: float = 0.0
    mean_quality_after: float = 0.0
    
    def __post_init__(self):
        # ä¸å†éœ€è¦æ‰‹åŠ¨åˆå§‹åŒ–ï¼Œfield(default_factory=list)å·²å¤„ç†
        pass


class FastpAgent:
    """
    FastPæ‰¹æ¬¡è´¨é‡æ§åˆ¶ä¸å‚æ•°ä¼˜åŒ–Agent
    
    ç»Ÿä¸€çš„æ‰¹æ¬¡å¤„ç†æ¶æ„ï¼Œæ”¯æŒï¼š
    - æ‰¹æ¬¡æ ·æœ¬å¤„ç†ï¼ˆå•æ ·æœ¬ä½œä¸ºæ‰¹æ¬¡å¤§å°1çš„ç‰¹ä¾‹ï¼‰
    - æ™ºèƒ½å‚æ•°ä¼˜åŒ–å»ºè®®ï¼ˆåŸºäºæ‰¹æ¬¡ç»“æœåˆ†æï¼‰
    - å®¹å™¨åŒ–Nextflowæ‰§è¡Œç¯å¢ƒ
    - LLMæ™ºèƒ½è´¨é‡è¯„ä¼°å’Œä¼˜åŒ–ç­–ç•¥
    """
    
    def __init__(self):
        """åˆå§‹åŒ–FastPæ‰¹æ¬¡å¤„ç†Agent"""
        self.config_manager = get_tools_config()
        # åˆå§‹åŒ–LLMç®¡ç†å™¨
        self.llm_manager = LLMManager(self.config_manager.settings)
        
    def validate_config(self, config: FastpConfig) -> Tuple[bool, List[str]]:
        """
        éªŒè¯é…ç½®å‚æ•°çš„æœ‰æ•ˆæ€§
        
        Args:
            config: FastPé…ç½®å¯¹è±¡
            
        Returns:
            (is_valid, error_messages): éªŒè¯ç»“æœå’Œé”™è¯¯ä¿¡æ¯åˆ—è¡¨
        """
        errors = []
        
        # éªŒè¯è¾“å…¥æ–‡ä»¶
        if not config.input_files:
            errors.append("è¾“å…¥æ–‡ä»¶åˆ—è¡¨ä¸èƒ½ä¸ºç©º")
        else:
            for file_path in config.input_files:
                file_obj = Path(file_path)
                if not file_obj.exists():
                    errors.append(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                elif file_obj.stat().st_size == 0:
                    errors.append(f"è¾“å…¥æ–‡ä»¶ä¸ºç©º: {file_path}")
        
        # éªŒè¯è¾“å‡ºç›®å½•
        if not config.output_dir:
            errors.append("è¾“å‡ºç›®å½•ä¸èƒ½ä¸ºç©º")
        else:
            output_path = Path(config.output_dir)
            try:
                output_path.mkdir(parents=True, exist_ok=True)
            except PermissionError:
                errors.append(f"æ— æƒé™åˆ›å»ºè¾“å‡ºç›®å½•: {config.output_dir}")
        
        # éªŒè¯æ ·æœ¬åç§°
        if not config.sample_name:
            errors.append("æ ·æœ¬åç§°ä¸èƒ½ä¸ºç©º")
        elif not config.sample_name.replace('_', '').replace('-', '').isalnum():
            errors.append("æ ·æœ¬åç§°åªèƒ½åŒ…å«å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿å’Œè¿å­—ç¬¦")
        
        # éªŒè¯è´¨é‡å‚æ•°
        if config.qualified_quality_phred < 0 or config.qualified_quality_phred > 40:
            errors.append("è´¨é‡é˜ˆå€¼å¿…é¡»åœ¨0-40ä¹‹é—´")
        
        if config.unqualified_percent_limit < 0 or config.unqualified_percent_limit > 100:
            errors.append("ä½è´¨é‡baseæ¯”ä¾‹é™åˆ¶å¿…é¡»åœ¨0-100ä¹‹é—´")
        
        if config.length_required < 1:
            errors.append("æœ€çŸ­é•¿åº¦è¦æ±‚å¿…é¡»å¤§äº0")
        
        return len(errors) == 0, errors
    
    def _parse_json_report_with_path(self, json_path: str, result: FastpResult) -> FastpResult:
        """ä½¿ç”¨è·¯å¾„è§£æfastp JSONæŠ¥å‘Šï¼Œæå–è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯"""
        try:
            import json
            with open(json_path, 'r') as f:
                data = json.load(f)
            
            # æå–summaryç»Ÿè®¡ä¿¡æ¯
            summary = data.get('summary', {})
            
            # æµ‹åºç±»å‹
            result.sequencing_type = summary.get('sequencing', 'unknown')
            
            # å¤„ç†å‰ç»Ÿè®¡
            before_filtering = summary.get('before_filtering', {})
            result.total_reads_before = before_filtering.get('total_reads', 0)
            result.total_bases_before = before_filtering.get('total_bases', 0)
            result.q20_bases_before = before_filtering.get('q20_bases', 0)
            result.q30_bases_before = before_filtering.get('q30_bases', 0)
            result.read_length_before = before_filtering.get('read1_mean_length', 0)
            result.gc_content_before = before_filtering.get('gc_content', 0.0)
            
            # å¤„ç†åç»Ÿè®¡
            after_filtering = summary.get('after_filtering', {})
            result.total_reads_after = after_filtering.get('total_reads', 0)
            result.total_bases_after = after_filtering.get('total_bases', 0)
            result.q20_bases_after = after_filtering.get('q20_bases', 0)
            result.q30_bases_after = after_filtering.get('q30_bases', 0)
            result.read_length_after = after_filtering.get('read1_mean_length', 0)
            result.gc_content_after = after_filtering.get('gc_content', 0.0)
            
            # è¿‡æ»¤ç»Ÿè®¡
            filtering_result = data.get('filtering_result', {})
            result.passed_filter_reads = filtering_result.get('passed_filter_reads', 0)
            result.low_quality_reads = filtering_result.get('low_quality_reads', 0)
            result.too_many_n_reads = filtering_result.get('too_many_N_reads', 0)
            result.too_short_reads = filtering_result.get('too_short_reads', 0)
            result.too_long_reads = filtering_result.get('too_long_reads', 0)
            
            # é‡å¤ç‡
            duplication = data.get('duplication', {})
            result.duplication_rate = duplication.get('rate', 0.0)
            
            # æ¥å¤´åˆ‡é™¤ä¿¡æ¯
            adapter_cutting = data.get('adapter_cutting', {})
            result.adapter_trimmed_reads = adapter_cutting.get('adapter_trimmed_reads', 0)
            result.adapter_trimmed_bases = adapter_cutting.get('adapter_trimmed_bases', 0)
            
            # æ£€æµ‹åˆ°çš„æ¥å¤´åºåˆ—
            if 'read1_adapter_sequence' in adapter_cutting:
                result.detected_adapters.append(adapter_cutting['read1_adapter_sequence'])
            if 'read2_adapter_sequence' in adapter_cutting:
                result.detected_adapters.append(adapter_cutting['read2_adapter_sequence'])
            
            # è¿‡åº¦è¡¨è¾¾åºåˆ—ç»Ÿè®¡
            overrep = data.get('read1_after_filtering', {}).get('overrepresented_sequences', {})
            if not overrep:  # å¦‚æœread1æ²¡æœ‰ï¼Œå°è¯•summaryçº§åˆ«
                overrep = data.get('overrepresented_sequences', {})
            
            if overrep:
                result.overrepresented_sequences = len(overrep)
                # æå–å‰5ä¸ªè¿‡åº¦è¡¨è¾¾åºåˆ—
                top_seqs = []
                for seq, count in sorted(overrep.items(), key=lambda x: x[1] if isinstance(x[1], int) else 0, reverse=True)[:5]:
                    top_seqs.append({'sequence': seq, 'count': count})
                result.top_overrepresented = top_seqs
                
        except Exception as e:
            # JSONè§£æå¤±è´¥ä¸å½±å“ä¸»è¦åŠŸèƒ½ï¼Œè®°å½•é”™è¯¯å³å¯
            result.error_message = f"è§£æJSONæŠ¥å‘Šå¤±è´¥: {str(e)}"
        
        return result
    
    def _parse_llm_json_response(self, response_text: str) -> Dict[str, Any]:
        """è§£æLLMè¿”å›çš„JSONå“åº”ï¼Œå¤„ç†ä»£ç å—æ ‡è®°"""
        # ç§»é™¤ä»£ç å—æ ‡è®°
        if response_text.startswith("```"):
            start_idx = response_text.find("{")
            end_idx = response_text.rfind("}") + 1
            if start_idx != -1 and end_idx > start_idx:
                response_text = response_text[start_idx:end_idx]
        
        import json
        return json.loads(response_text)
    
    def _get_llm_group_summary_and_params(
        self,
        samples: List[Dict[str, Any]],
        base_params: Dict[str, Any],
        history: Optional[List[Dict[str, Any]]] = None,
    ) -> Dict[str, Any]:
        """
        ç»Ÿä¸€çš„LLMåˆ†ææ–¹æ³•ï¼šå°†æ‰€æœ‰æ ·æœ¬ç»“æœæäº¤ç»™LLMï¼Œè·å–æ€»ç»“ä¸å‚æ•°å»ºè®®
        
        è¿”å›ç»“æ„ï¼š
        {
          "suggested_params": {k: v, ...},   # ä»…éœ€å˜æ›´çš„é”®ï¼›ä½œä¸ºè¦†ç›–é¡¹
          "reasoning": "...",               # å‚æ•°æ¨èç†ç”±ï¼ˆä¸­æ–‡ï¼‰
          "group_summary": "...",           # é¢å‘ç”¨æˆ·çš„æ•´ä½“è´¨é‡æ€»ç»“ï¼ˆä¸­æ–‡ï¼‰
          "sample_assessments": {"sample_id": "è´¨é‡è¯„çº§", ...}  # å„æ ·æœ¬è´¨é‡è¯„çº§
        }
        """
        # æå–å®Œæ•´çš„æ ·æœ¬ç»Ÿè®¡ä¿¡æ¯ä¾›LLMåˆ†æ
        compact = []
        for s in samples:
            if not s.get("success"):
                compact.append({
                    "sample_id": s.get("sample_id"),
                    "success": False,
                    "error": s.get("error", "æœªçŸ¥é”™è¯¯")
                })
                continue
                
            stats = s.get("statistics", {})
            
            # ä»resultsä¸­å·²æœ‰çš„ç»Ÿè®¡æ•°æ®æ„å»ºå®Œæ•´ä¿¡æ¯
            sample_info = {
                "sample_id": s.get("sample_id"),
                "success": True,
                # åŸºæœ¬ç»Ÿè®¡ - è¿™äº›åœ¨ run_batch ä¸­å·²ç»è®¡ç®—å¥½äº†
                "reads_before": stats.get("reads_before", 0),
                "reads_after": stats.get("reads_after", 0),
                "reads_retention": stats.get("reads_retention", 0.0),
                "q30_rate": stats.get("q30_rate", 0.0),
                # ä» FastpResult ä¸­æå–çš„é¢å¤–ä¿¡æ¯
                "gc_content_before": stats.get("gc_content_before", 0.0),
                "gc_content_after": stats.get("gc_content_after", 0.0),
                "mean_length_before": stats.get("mean_length_before", 0.0),
                "mean_length_after": stats.get("mean_length_after", 0.0),
                "duplication_rate": stats.get("duplication_rate", 0.0),
                "adapter_trimmed_reads": stats.get("adapter_trimmed_reads", 0),
                "adapter_trimmed_percent": stats.get("adapter_trimmed_percent", 0.0),
                # è¿‡æ»¤åŸå› ç»Ÿè®¡
                "low_quality_reads": stats.get("low_quality_reads", 0),
                "too_short_reads": stats.get("too_short_reads", 0),
                "too_many_n_reads": stats.get("too_many_n_reads", 0),
            }
            
            compact.append(sample_info)

        import json as _json
        sys_prompt = (
            "ä½ æ˜¯èµ„æ·±ç”Ÿä¿¡è´¨æ§å·¥ç¨‹å¸ˆã€‚è¯·åŸºäºä¸€ç»„ fastp ç»“æœç»™å‡ºæ•´ä½“æ€»ç»“å¹¶æ¨èå‚æ•°ã€‚"
            " è¾“å‡ºä¸¥æ ¼ JSONï¼ˆä¸å«ä»£ç å—ã€æ³¨é‡Šï¼‰ï¼Œé”®ä¸º suggested_paramsã€reasoningã€group_summaryã€sample_assessmentsã€‚"
            " é‡è¦ï¼šè‹¥åœ¨ reasoning ä¸­æåˆ°ä»»ä½•å‚æ•°è°ƒæ•´ï¼Œå¿…é¡»åœ¨ suggested_params ä¸­ç»™å‡ºå¯¹åº” fastp å‚æ•°é”®ä¸ç›®æ ‡å€¼ï¼Œä¸”ä»…åŒ…å«éœ€è¦å˜æ›´çš„é”®ï¼ˆä¸åŸºç¡€å‚æ•°ç›¸åŒçš„å€¼ä¸è¦åŒ…å«ï¼‰ã€‚"
            " sample_assessments æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œé”®ä¸ºsample_idï¼Œå€¼ä¸ºè´¨é‡è¯„çº§ï¼ˆä¼˜ç§€/è‰¯å¥½/åˆæ ¼/éœ€æ”¹è¿›/å·®ï¼‰ã€‚"
        )

        # æ„å»ºæç¤ºè¯ï¼Œé¿å…f-stringä¸­çš„æ ¼å¼åŒ–é—®é¢˜
        base_params_str = _json.dumps(base_params, ensure_ascii=False)
        compact_str = _json.dumps(compact, ensure_ascii=False, indent=2)
        
        # æœ€è¿‘å†å²ï¼ˆæœ€å¤š3æ¬¡ï¼‰å¯é€‰ä¸Šä¸‹æ–‡ï¼›è‹¥æœªæä¾›åˆ™ä¸ºç©º
        history = history or []
        recent = history[-3:] if len(history) > 3 else history
        history_compact = []
        for history_entry in recent:
            history_compact.append({
                "version": history_entry.get("version"),
                "applied_params": history_entry.get("params", {}),
                "suggested": history_entry.get("optimized_params", {}),
                "success_rate": history_entry.get("execution_result", {}).get("success_rate", 0),
            })
        history_str = _json.dumps(history_compact, ensure_ascii=False, indent=2)
        
        param_prompt = f"""
åŸºç¡€å‚æ•°ï¼ˆå¯ä½œä¸ºé»˜è®¤æˆ–ä¸‹é™çº¦æŸï¼‰ï¼š
{base_params_str}

æ ·æœ¬ç»Ÿè®¡ï¼ˆåŒ…å«è¯¦ç»†è´¨é‡æŒ‡æ ‡ï¼‰ï¼š
{compact_str}

æœ€è¿‘å†å²ï¼ˆè¯·æ ¹æ®å†å²æ¥å†³å®šå‚æ•°ï¼Œé¿å…åå¤è°ƒèŠ‚åŒæ ·çš„å‚æ•°ï¼‰ï¼š
{history_str}

è¯·åŸºäºä»¥ä¸‹æŒ‡æ ‡è¯„ä¼°æ¯ä¸ªæ ·æœ¬çš„è´¨é‡ï¼š
- reads_retention: readsä¿ç•™ç‡ï¼ˆ>80%ä¼˜ç§€ï¼Œ70-80%è‰¯å¥½ï¼Œ60-70%åˆæ ¼ï¼Œ50-60%éœ€æ”¹è¿›ï¼Œ<50%å·®ï¼‰
- q30_rate: Q30ç¢±åŸºæ¯”ä¾‹ï¼ˆ>90%ä¼˜ç§€ï¼Œ80-90%è‰¯å¥½ï¼Œ70-80%åˆæ ¼ï¼Œ60-70%éœ€æ”¹è¿›ï¼Œ<60%å·®ï¼‰
- gc_content: GCå«é‡å˜åŒ–ï¼ˆå˜åŒ–<5%æ­£å¸¸ï¼Œ5-10%è½»å¾®å¼‚å¸¸ï¼Œ>10%å¼‚å¸¸ï¼‰
- duplication_rate: é‡å¤ç‡ï¼ˆ<10%ä¼˜ç§€ï¼Œ10-20%è‰¯å¥½ï¼Œ20-30%åˆæ ¼ï¼Œ30-40%éœ€æ”¹è¿›ï¼Œ>40%å·®ï¼‰
- adapter_trimmed_percent: æ¥å¤´æ±¡æŸ“ï¼ˆ<5%ä¼˜ç§€ï¼Œ5-10%è‰¯å¥½ï¼Œ10-20%åˆæ ¼ï¼Œ20-30%éœ€æ”¹è¿›ï¼Œ>30%å·®ï¼‰

è¯·ï¼š
1) è¯„ä¼°æ¯ä¸ªæ ·æœ¬çš„è´¨é‡ç­‰çº§ï¼Œåœ¨ sample_assessments ä¸­è¿”å› {{"sample_id": "è´¨é‡è¯„çº§"}} çš„æ˜ å°„
2) ä»¥ä¸­æ–‡æ€»ç»“æ•´ä½“è´¨é‡ã€æ½œåœ¨é—®é¢˜ã€æ ·æœ¬é—´å·®å¼‚ï¼Œå†™å…¥ group_summary
3) ç»™å‡ºè°¨æ…ä¸”é€šç”¨çš„ fastp å‚æ•°å»ºè®®ï¼ˆä»…åˆ—å‡ºéœ€è¦å˜æ›´çš„é”®åŠç›®æ ‡å€¼ï¼‰ï¼Œå†™å…¥ suggested_params
4) **é‡è¦ï¼šå¿…é¡»åœ¨ reasoning ä¸­æä¾›å‚æ•°å†³ç­–ç†ç”±**ï¼š
   - å¦‚æœæœ‰å‚æ•°å»ºè®®ï¼Œè¯·è§£é‡Šä¸ºä»€ä¹ˆå»ºè®®è¿™äº›å˜æ›´åŠå…¶é¢„æœŸæ•ˆæœ
   - å¦‚æœæ— éœ€è°ƒæ•´å‚æ•°ï¼Œè¯·è¯´æ˜"å½“å‰å‚æ•°é…ç½®é€‚åˆæœ¬æ‰¹æ ·æœ¬ï¼Œè´¨é‡æŒ‡æ ‡ç¬¦åˆé¢„æœŸ"
   - reasoningå­—æ®µä¸èƒ½ä¸ºç©ºï¼Œè‡³å°‘è¦æœ‰30ä¸ªä¸­æ–‡å­—ç¬¦çš„è§£é‡Š

è¾“å‡ºè§„èŒƒï¼ˆä¸¥æ ¼éµå®ˆï¼‰ï¼š
- ä»…è¾“å‡ºä»¥ä¸‹ fastp é”®ï¼ˆç™½åå•ï¼‰ï¼š
  qualified_quality_phred, unqualified_percent_limit, n_base_limit, length_required,
  adapter_trimming, quality_filtering, length_filtering, phred64, reads_to_process, fix_mgi_id,
  detect_adapter_for_pe, trim_front1, trim_tail1, max_len1, trim_front2, trim_tail2, max_len2,
  trim_poly_g, poly_g_min_len, disable_trim_poly_g, trim_poly_x, poly_x_min_len,
  cut_front, cut_tail, cut_right, cut_window_size, cut_mean_quality, cut_front_window_size,
  cut_front_mean_quality, cut_tail_window_size, cut_tail_mean_quality, cut_right_window_size,
  cut_right_mean_quality, average_qual, disable_length_filtering, length_limit, low_complexity_filter,
  complexity_threshold, correction, overlap_len_require, overlap_diff_limit, overlap_diff_percent_limit,
  overrepresentation_analysis, overrepresentation_samplingã€‚
- ç±»å‹å¿…é¡»ä¸åŸºç¡€å‚æ•°ä¸€è‡´ï¼šå¸ƒå°”å€¼ä½¿ç”¨ true/falseï¼›æ•´æ•°/æ•°å€¼ä¸å¾—ä½¿ç”¨å­—ç¬¦ä¸²è¡¨ç¤ºï¼›ä¸å¾—è¾“å‡º nullã€‚
- suggested_params åªèƒ½åŒ…å«â€œä¸åŸºç¡€å‚æ•° base_params ä¸åŒâ€çš„é”®å€¼ï¼›ä¸è¦å›æ˜¾ç›¸åŒå€¼ã€‚
- è‹¥ reasoning å‡ºç°â€œå»ºè®®/å¯ç”¨/é™ä½/æé«˜/é˜ˆå€¼/polyG/ä½å¤æ‚åº¦â€ç­‰å­—æ ·ï¼Œåˆ™ suggested_params ä¸å¾—ä¸ºç©ºã€‚
- è‹¥ç¡®å®æ— éœ€è°ƒæ•´ï¼Œè¯·è¿”å›ç©ºå¯¹è±¡ {{}} å¹¶åœ¨ reasoning æ˜ç¡®å†™â€œæ— éœ€è°ƒæ•´â€ã€‚

ç¤ºä¾‹ï¼ˆä»…ç¤ºæ„ï¼Œä¸è¦ç…§æŠ„ï¼‰ï¼š
{{
  "suggested_params": {{
    "trim_poly_g": true,
    "poly_g_min_len": 10,
    "low_complexity_filter": true,
    "complexity_threshold": 20
  }},
  "reasoning": "é‡å¤ç‡åé«˜ä¸”æœ«ç«¯è´¨é‡ä¸‹é™ï¼Œå¯ç”¨polyGå¹¶è®¾ç½®æœ€å°é•¿åº¦10ï¼›å¼€å¯ä½å¤æ‚åº¦è¿‡æ»¤å¹¶é™ä½é˜ˆå€¼è‡³20ï¼Œå°½é‡ä¸å½±å“readsä¿ç•™ç‡ã€‚",
  "group_summary": "æ€»ä½“è´¨é‡ä¼˜ç§€ä½†å­˜åœ¨é‡å¤ç‡åé«˜â€¦",
  "sample_assessments": {{"S1": "è‰¯å¥½", "S2": "è‰¯å¥½"}}
}}

æœ€ç»ˆä»…è¾“å‡º JSON å¯¹è±¡ï¼š{{"suggested_params":{{}},"reasoning":"","group_summary":"","sample_assessments":{{}}}}
"""
        
        try:
            llm = self.llm_manager.get_llm()
            resp = llm.invoke([HumanMessage(content=sys_prompt + "\n\n" + param_prompt)])
            content = resp.content if hasattr(resp, "content") else str(resp)
            
            # è§£æJSONå“åº”
            parsed = self._parse_llm_json_response(str(content))
            
            # å…œåº•ç»“æ„æ ¡éªŒ
            if not isinstance(parsed, dict):
                raise ValueError("LLMè¾“å‡ºéå­—å…¸")
            parsed.setdefault("suggested_params", {})
            parsed.setdefault("reasoning", "")
            parsed.setdefault("group_summary", "")
            parsed.setdefault("sample_assessments", {})
            
            # ç¡®ä¿ reasoning å­—æ®µä¸ä¸ºç©º
            if not parsed["reasoning"].strip():
                if parsed.get("suggested_params"):
                    parsed["reasoning"] = "åŸºäºè´¨é‡æŒ‡æ ‡åˆ†æï¼Œæä¾›äº†å‚æ•°ä¼˜åŒ–å»ºè®®ä»¥æ”¹å–„æ•°æ®è´¨é‡ã€‚"
                else:
                    parsed["reasoning"] = "å½“å‰å‚æ•°é…ç½®é€‚åˆæœ¬æ‰¹æ ·æœ¬ï¼Œè´¨é‡æŒ‡æ ‡ç¬¦åˆé¢„æœŸï¼Œæ— éœ€è°ƒæ•´ã€‚"
            
            return parsed
            
        except Exception as e:
            print(f"âš ï¸ LLMç»„çº§åˆ†æå¤±è´¥: {str(e)}")
            # è¿”å›ç©ºç»“æœï¼Œè®©è°ƒç”¨æ–¹ä½¿ç”¨å¤‡é€‰æ–¹æ³•
            return {
                "suggested_params": {},
                "reasoning": f"LLMåˆ†æå¤±è´¥: {str(e)}",
                "group_summary": "",
                "sample_assessments": {}
            }
    
    
    def _get_base_params_from_nf(self, nextflow_config_values: Dict[str, Any]) -> Dict[str, Any]:
        """ä» nextflow_config æå–ï¼ˆæˆ–é»˜è®¤ç”Ÿæˆï¼‰fastp å…¨é‡åŸºç¡€å‚æ•°æ¨¡æ¿ã€‚

        è¯´æ˜ï¼šä¿ç•™é¡¹ç›®å…ˆå‰æ—¢å®šé»˜è®¤ï¼ˆå¦‚ Q20=20ã€length_required=15ï¼‰ï¼Œ
        å…¶ä½™å‚æ•°è¡¥é½å¹¶ç»™å‡ºä¸ fastp è¯­ä¹‰ä¸€è‡´çš„ä¿å®ˆé»˜è®¤å€¼ã€‚
        """
        return {
            # æ ¸å¿ƒè´¨é‡/é•¿åº¦è¿‡æ»¤ï¼ˆä¿æŒç°æœ‰é»˜è®¤ï¼‰
            "qualified_quality_phred": nextflow_config_values.get("qualified_quality_phred", 20),  # -q
            "unqualified_percent_limit": nextflow_config_values.get("unqualified_percent_limit", 40),  # -u
            "n_base_limit": nextflow_config_values.get("n_base_limit", 5),  # -n
            "length_required": nextflow_config_values.get("length_required", 15),  # -l
            "adapter_trimming": nextflow_config_values.get("adapter_trimming", True),
            "quality_filtering": nextflow_config_values.get("quality_filtering", True),
            "length_filtering": nextflow_config_values.get("length_filtering", True),  # åå‘å¯¹åº” -L

            # è¾“å…¥è´¨é‡ä¸è¯»å–æ§åˆ¶
            "phred64": nextflow_config_values.get("phred64", False),  # -6/--phred64
            "reads_to_process": nextflow_config_values.get("reads_to_process", 0),  # --reads_to_process (0=å…¨éƒ¨)
            "fix_mgi_id": nextflow_config_values.get("fix_mgi_id", False),  # --fix_mgi_id
            "detect_adapter_for_pe": nextflow_config_values.get("detect_adapter_for_pe", None),  # --detect_adapter_for_peï¼ˆé»˜è®¤Noneï¼Œæ‰¹é‡é€»è¾‘å¦è¡Œå†³å®šï¼‰

            # å‰åç«¯å®šé•¿ä¿®å‰ªä¸æœ€å¤§é•¿åº¦
            "trim_front1": nextflow_config_values.get("trim_front1", 0),  # -f
            "trim_tail1": nextflow_config_values.get("trim_tail1", 0),  # -t
            "max_len1": nextflow_config_values.get("max_len1", 0),  # -b (0=æ— é™åˆ¶)
            "trim_front2": nextflow_config_values.get("trim_front2", 0),  # -F
            "trim_tail2": nextflow_config_values.get("trim_tail2", 0),  # -T
            "max_len2": nextflow_config_values.get("max_len2", 0),  # -B (0=æ— é™åˆ¶)

            # polyG / polyX ä¿®å‰ª
            "trim_poly_g": nextflow_config_values.get("trim_poly_g", False),  # -g
            "poly_g_min_len": nextflow_config_values.get("poly_g_min_len", None),  # --poly_g_min_lenï¼ˆä»…åœ¨å¯ç”¨ -g æ—¶ç”Ÿæ•ˆï¼‰
            "disable_trim_poly_g": nextflow_config_values.get("disable_trim_poly_g", False),  # -G
            "trim_poly_x": nextflow_config_values.get("trim_poly_x", False),  # -x
            "poly_x_min_len": nextflow_config_values.get("poly_x_min_len", None),  # --poly_x_min_len

            # æ»‘çª—åˆ‡é™¤å¼€å…³ï¼ˆcut_* å¼€å…³ä½¿ç”¨å¸ƒå°”å€¼æ§åˆ¶å¯ç”¨/ç¦ç”¨ï¼‰
            "cut_front": nextflow_config_values.get("cut_front", False),   # -5 å¯ç”¨å‰ç«¯åˆ‡é™¤
            "cut_tail": nextflow_config_values.get("cut_tail", False),     # -3 å¯ç”¨åç«¯åˆ‡é™¤  
            "cut_right": nextflow_config_values.get("cut_right", False),   # -r å¯ç”¨å³ç«¯åˆ‡é™¤
            "cut_window_size": nextflow_config_values.get("cut_window_size", 4),  # -W
            "cut_mean_quality": nextflow_config_values.get("cut_mean_quality", 20),  # -M
            # å…·ä½“çª—å£ä¸è´¨é‡ï¼ˆæœªæŒ‡å®šæ—¶æ²¿ç”¨å…¨å±€çª—å£ä¸è´¨é‡é—¨é™ï¼Œç»™å‡ºæ˜¾å¼é»˜è®¤ä»¥ä¾¿æ¨¡æ¿å®Œæ•´ï¼‰
            "cut_front_window_size": nextflow_config_values.get("cut_front_window_size", 4),
            "cut_front_mean_quality": nextflow_config_values.get("cut_front_mean_quality", 20),
            "cut_tail_window_size": nextflow_config_values.get("cut_tail_window_size", 4),
            "cut_tail_mean_quality": nextflow_config_values.get("cut_tail_mean_quality", 20),
            "cut_right_window_size": nextflow_config_values.get("cut_right_window_size", 4),
            "cut_right_mean_quality": nextflow_config_values.get("cut_right_mean_quality", 20),

            # è´¨é‡/é•¿åº¦è¿‡æ»¤ç»†åŒ–
            "average_qual": nextflow_config_values.get("average_qual", 0),  # -e (0=ä¸å¯ç”¨)
            "disable_length_filtering": nextflow_config_values.get("disable_length_filtering", False),  # -L
            "length_limit": nextflow_config_values.get("length_limit", 0),  # --length_limit (0=æ— é™åˆ¶)
            "low_complexity_filter": nextflow_config_values.get("low_complexity_filter", False),  # -y
            "complexity_threshold": nextflow_config_values.get("complexity_threshold", 30),  # -Y

            # PE é‡å æ ¡æ­£ä¸æ£€æµ‹
            "correction": nextflow_config_values.get("correction", False),  # -cï¼ˆä»…PEï¼‰
            "overlap_len_require": nextflow_config_values.get("overlap_len_require", 30),
            "overlap_diff_limit": nextflow_config_values.get("overlap_diff_limit", 5),
            "overlap_diff_percent_limit": nextflow_config_values.get("overlap_diff_percent_limit", 20),

            # è¿‡è¡¨è¾¾åºåˆ—åˆ†æ
            "overrepresentation_analysis": nextflow_config_values.get("overrepresentation_analysis", False),  # -p
            "overrepresentation_sampling": nextflow_config_values.get("overrepresentation_sampling", 20),  # -P
        }


    def _summarize_batch(self, results: List[Dict[str, Any]], base_params: Dict[str, Any], optimized_params: Dict[str, Any], sample_assessments: Optional[Dict[str, str]] = None) -> str:
        """ç”Ÿæˆæ‰¹æ¬¡å¤„ç†çš„æ€»ç»“æŠ¥å‘Š"""
        total = len(results)
        successful = sum(1 for r in results if r.get("success"))
        summary = [
            "\nğŸ§¬ FastPè´¨æ§å¤„ç†å®Œæˆ",
            "",
            "ğŸ“Š å¤„ç†ç»Ÿè®¡:",
            f"- æ€»æ ·æœ¬æ•°: {total}",
            f"- æˆåŠŸå¤„ç†: {successful}",
            f"- å¤±è´¥æ ·æœ¬: {total - successful}",
            "",
            "ğŸ“‹ æ ·æœ¬è¯¦æƒ…:",
        ]

        for r in results:
            if r.get("success"):
                stats = r.get("statistics", {})
                retention = stats.get("reads_retention", 0) * 100
                q30_rate = stats.get("q30_rate", 0) * 100
                quality = sample_assessments.get(r['sample_id'], 'æœªè¯„çº§') if sample_assessments else 'æœªè¯„çº§'
                summary.append(f"- {r['sample_id']}: âœ… æˆåŠŸ ({quality})")
                summary.append(f"  ä¿ç•™ç‡: {retention:.1f}% | Q30: {q30_rate:.1f}%")
            else:
                summary.append(f"- {r['sample_id']}: âŒ å¤±è´¥ - {r.get('error', 'unknown')}")

        summary.append("")
        summary.append("ğŸ§  ç»„çº§å‚æ•°å»ºè®® (Fastp)ï¼š")
        changed = False
        for k in sorted(optimized_params.keys()):
            b = base_params.get(k)
            o = optimized_params.get(k)
            if b != o:
                summary.append(f"- {k}: {b} -> {o}")
                changed = True
        if not changed:
            summary.append("- æ— éœ€è°ƒæ•´ï¼Œä¿ç•™é»˜è®¤å‚æ•°")

        return "\n".join(summary)

    
    def run_batch(
        self,
        sample_groups: List[Dict[str, Any]],
        nextflow_config: Dict[str, Any],
        current_params: Optional[Dict[str, Any]] = None,
        version: int = 1,
        version_history: Optional[List[Dict[str, Any]]] = None
    ) -> Dict[str, Any]:
        """å•æ¬¡ Nextflow æ‰¹é‡æ‰§è¡Œ fastpï¼Œå¹¶ç”Ÿæˆç»„çº§å»ºè®®ä¸æ€»ç»“ã€‚
        
        Args:
            sample_groups: æ ·æœ¬ç»„ä¿¡æ¯
            nextflow_config: Nextflowé…ç½®
            current_params: å½“å‰è¿è¡Œå‚æ•°ï¼ˆè°ƒç”¨æ–¹ä¼ å…¥ï¼Œæ¨èæ¥è‡ª state.fastp_paramsï¼‰
            version: å‚æ•°ç‰ˆæœ¬å·ï¼Œç”¨äºæ–‡ä»¶å‘½å
        """
        # å­˜å‚¨å…¨å±€é…ç½®ä¾›å…¶ä»–æ–¹æ³•ä½¿ç”¨
        self._global_nextflow_config = nextflow_config or {}

        from pathlib import Path

        # ç»“æœæ ¹ç›®å½•ï¼šä½¿ç”¨ nextflow_config.results_dir
        results_root = Path(nextflow_config["results_dir"]) / "fastp"
        results_root.mkdir(parents=True, exist_ok=True)

        # 1. ä¼˜å…ˆä½¿ç”¨current_paramsï¼ˆæ¥è‡ªstateçš„å†å²ä¼˜åŒ–å‚æ•°ï¼‰
        # 2. å…¶æ¬¡ä½¿ç”¨nextflow_configä¸­çš„æ˜¾å¼é…ç½®
        # 3. æœ€åä½¿ç”¨ç³»ç»Ÿé»˜è®¤å‚æ•°
        base_params = self._get_base_params_from_nf(nextflow_config or {})
        
        # å¦‚æœæœ‰å†å²ä¼˜åŒ–å‚æ•°ï¼Œä¼˜å…ˆä½¿ç”¨
        if current_params:
            print(f"ğŸ”„ ä½¿ç”¨å†å²ä¼˜åŒ–å‚æ•°: {len(current_params)} ä¸ªå‚æ•°")
            effective_params = base_params.copy()
            effective_params.update(current_params)
        else:
            print(f"ğŸ†• ä½¿ç”¨é»˜è®¤å‚æ•°é…ç½®")
            effective_params = base_params

        # CPUèµ„æºï¼šä»…é€šè¿‡ Nextflow çš„ fastp_cpus ç®¡ç†
        fastp_cpus = (nextflow_config or {}).get('fastp_cpus')

        # detect_adapter_for_peï¼šä¼˜å…ˆä½¿ç”¨ fastp_paramsï¼ˆeffective_paramsï¼‰ï¼›ç¼ºçœæ—¶è‹¥ä»»ä¸€ç»„ä¸ºPEåˆ™é»˜è®¤å¼€å¯
        any_paired = any(bool(sample_group.get("read2")) for sample_group in (sample_groups or []))

        # æ„å»ºæ‰¹é‡ params å­—å…¸
        batch_params: Dict[str, Any] = {
            "sample_groups": sample_groups or [],
            "results_dir": str(results_root.parent),  # fastp.nf ä¼šæ‹¼æ¥ fastp/${sample_id}
        }
        if fastp_cpus is not None:
            batch_params["fastp_cpus"] = int(fastp_cpus)

        # åˆå¹¶æœ‰æ•ˆ fastp å‚æ•°ï¼ˆä¼˜å…ˆä½¿ç”¨å†å²ä¼˜åŒ–å‚æ•°ï¼‰
        batch_params.update({
            "qualified_quality_phred": effective_params.get("qualified_quality_phred", 20),
            "unqualified_percent_limit": effective_params.get("unqualified_percent_limit", 40),
            "n_base_limit": effective_params.get("n_base_limit", 5),
            "length_required": effective_params.get("length_required", 15),
            "adapter_trimming": effective_params.get("adapter_trimming", True),
            "quality_filtering": effective_params.get("quality_filtering", True),
            "length_filtering": effective_params.get("length_filtering", True),
            "detect_adapter_for_pe": effective_params.get("detect_adapter_for_pe") if effective_params.get("detect_adapter_for_pe") is not None else any_paired,
        })

        # æ·»åŠ é«˜çº§å‚æ•°ï¼ˆä¼˜å…ˆä»effective_paramsè¯»å–ï¼‰
        advanced_params = {
            "average_qual", "length_limit", "low_complexity_filter", "trim_poly_g", "disable_trim_poly_g",
            "trim_poly_x", "poly_g_min_len", "poly_x_min_len", "cut_front", "cut_tail",
            "cut_right", "cut_window_size", "cut_mean_quality", "cut_front_window_size",
            "cut_front_mean_quality", "cut_tail_window_size", "cut_tail_mean_quality",
            "cut_right_window_size", "cut_right_mean_quality", "correction", "complexity_threshold",
            "overlap_len_require", "overlap_diff_limit", "overlap_diff_percent_limit",
            "overrepresentation_sampling"
        }
        
        # ä»effective_paramsä¸­æ·»åŠ é«˜çº§å‚æ•°
        for param in advanced_params:
            if param in effective_params:
                batch_params[param] = effective_params[param]

        # ä¸å†è®© nextflow_config è¦†ç›– fastp å‚æ•°ï¼šfastp_params æ˜¯å”¯ä¸€çœŸç›¸æº
        # è‹¥éœ€è¦é€šè¿‡ nextflow_config æ˜¾å¼æ³¨å…¥ fastp ç›¸å…³é”®ï¼Œåº”åœ¨ Prepare é˜¶æ®µåŒæ­¥å†™å…¥ fastp_params

        # å†™å…¥ç‰ˆæœ¬åŒ–å‚æ•°æ–‡ä»¶
        params_file = results_root / f"fastp_params.v{version}.json"
        params_file_latest = results_root / "fastp_params.batch.json"  # Nextflowæ‰§è¡Œç”¨çš„æ–‡ä»¶
        
        print(f"ğŸ“‹ ä¿å­˜å‚æ•°é…ç½®: v{version} (ç‰ˆæœ¬åŒ–ç®¡ç†)")
        
        # ä¿å­˜ç‰ˆæœ¬åŒ–å‚æ•°æ–‡ä»¶ï¼ˆå¸¦æ—¶é—´æˆ³å’Œç‰ˆæœ¬ä¿¡æ¯ï¼‰
        versioned_config = {
            "version": version,
            "timestamp": __import__('datetime').datetime.now().isoformat(),
            "description": f"FastPå‚æ•°é…ç½® v{version}",
            "config": batch_params.copy()
        }
        
        with open(params_file, 'w', encoding='utf-8') as f:
            json.dump(versioned_config, f, indent=2, ensure_ascii=False)
        
        # åŒæ—¶ä¿å­˜ä¸ºNextflowæ‰§è¡Œç”¨çš„æ ‡å‡†æ–‡ä»¶å
        with open(params_file_latest, 'w', encoding='utf-8') as f:
            json.dump(batch_params, f, indent=2, ensure_ascii=False)

        # è¿è¡Œ Nextflowï¼ˆä½¿ç”¨æ ‡å‡†æ–‡ä»¶åï¼‰
        cmd = ["nextflow", "run", "/fastp.nf", "-params-file", str(params_file_latest), "-resume"]
        print("ğŸš€ æ‰§è¡Œæ‰¹é‡ fastp:", " ".join(cmd))
        completed_process = subprocess.run(cmd, capture_output=True, text=True, timeout=7200)

        if completed_process.returncode != 0:
            print(f"âš ï¸ Nextflowè¿”å›éé›¶çŠ¶æ€ç : {completed_process.returncode}")
            print(f"   stderr: {completed_process.stderr[:200]}...")
            # ä½†ä»ç»§ç»­æ£€æŸ¥è¾“å‡ºæ–‡ä»¶ï¼Œå› ä¸ºå¯èƒ½åªæ˜¯è­¦å‘Š
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ ·æœ¬æˆåŠŸäº§ç”Ÿè¾“å‡ºæ–‡ä»¶
        successful_samples = 0
        for sample_group in sample_groups or []:
            sample_id = sample_group.get("sample_id", "unknown")
            sample_dir = results_root / sample_id
            json_file = sample_dir / f"{sample_id}.fastp.json"
            if json_file.exists():
                successful_samples += 1
        
        if successful_samples == 0:
            # å®Œå…¨å¤±è´¥ï¼šè¿”å›ç»Ÿä¸€é”™è¯¯
            return {
                "samples": [
                    {"sample_id": sample_group.get("sample_id", "unknown"), "success": False, "error": completed_process.stderr}
                    for sample_group in (sample_groups or [])
                ],
                "default_params": base_params,
                "optimized_params": {},
                "summary": f"æ‰¹é‡æ‰§è¡Œå¤±è´¥: {completed_process.stderr[:200]}",
                "reasoning": "",
                "total": len(sample_groups or []),
                "success_count": 0,
                "version": version,
                "version_files": {
                    "versioned": str(params_file),
                    "latest": str(params_file_latest)
                },
            }
        elif completed_process.returncode != 0:
            print(f"ğŸ”§ Nextflowæœ‰è­¦å‘Šä½†{successful_samples}/{len(sample_groups)}æ ·æœ¬æˆåŠŸï¼Œç»§ç»­åˆ†æ")

        # æˆåŠŸï¼šé€æ ·æœ¬æ”¶é›†æŠ¥å‘Šå¹¶åšåˆ†æ
        results: List[Dict[str, Any]] = []
        for sample_group in sample_groups or []:
            sample_id = sample_group.get("sample_id") or "unknown"
            sample_output_dir = results_root / sample_id
            # æ„é€  FastpResult å¹¶ä»æŠ¥å‘Šå¡«å……
            fastp_result = FastpResult(success=True, exit_code=0)
            # æŠ¥å‘Šè·¯å¾„
            html_report_path = sample_output_dir / f"{sample_id}.fastp.html"
            json_report_path = sample_output_dir / f"{sample_id}.fastp.json"
            if html_report_path.exists():
                fastp_result.html_report = str(html_report_path)
            if json_report_path.exists():
                fastp_result.json_report = str(json_report_path)
                fastp_result = self._parse_json_report_with_path(str(json_report_path), fastp_result)
            else:
                fastp_result.success = False
                fastp_result.error_message = "ç¼ºå°‘ fastp JSON æŠ¥å‘Š"

            # è¾“å‡ºæ–‡ä»¶
            if sample_group.get("read2"):
                # PE
                trimmed_read1_path = sample_output_dir / f"{sample_id}_1.trimmed.fastq.gz"
                trimmed_read2_path = sample_output_dir / f"{sample_id}_2.trimmed.fastq.gz"
                output_files_list: List[str] = []
                if trimmed_read1_path.exists():
                    output_files_list.append(str(trimmed_read1_path))
                if trimmed_read2_path.exists():
                    output_files_list.append(str(trimmed_read2_path))
                fastp_result.output_files = output_files_list
            else:
                # SE
                single_trimmed_path = sample_output_dir / f"{sample_id}.single.trimmed.fastq.gz"
                if single_trimmed_path.exists():
                    fastp_result.output_files = [str(single_trimmed_path)]


            sample_result: Dict[str, Any] = {
                "sample_id": sample_id,
                "success": fastp_result.success,
                "statistics": {
                    # åŸºæœ¬ç»Ÿè®¡
                    "reads_before": fastp_result.total_reads_before,
                    "reads_after": fastp_result.total_reads_after,
                    "reads_retention": fastp_result.total_reads_after / fastp_result.total_reads_before if fastp_result.total_reads_before > 0 else 0,
                    "q30_rate": fastp_result.q30_bases_after / fastp_result.total_bases_after if fastp_result.total_bases_after > 0 else 0,
                    # é¢å¤–çš„è´¨é‡æŒ‡æ ‡
                    "gc_content_before": fastp_result.gc_content_before,
                    "gc_content_after": fastp_result.gc_content_after,
                    "mean_length_before": fastp_result.read_length_before,
                    "mean_length_after": fastp_result.read_length_after,
                    "duplication_rate": fastp_result.duplication_rate,
                    "adapter_trimmed_reads": fastp_result.adapter_trimmed_reads,
                    "adapter_trimmed_percent": fastp_result.adapter_trimmed_reads / fastp_result.total_reads_before if fastp_result.total_reads_before > 0 else 0,
                    # è¿‡æ»¤åŸå› ç»Ÿè®¡
                    "low_quality_reads": fastp_result.low_quality_reads,
                    "too_short_reads": fastp_result.too_short_reads,
                    "too_many_n_reads": fastp_result.too_many_n_reads,
                },
                "output_files": fastp_result.output_files,
                "reports": {"html": fastp_result.html_report, "json": fastp_result.json_report},
            }
            if not fastp_result.success:
                sample_result["error"] = fastp_result.error_message

            results.append(sample_result)

        # ä¼˜å…ˆï¼šä¸€æ¬¡æ€§ LLM ç»„çº§æ€»ç»“ + å‚æ•°å»ºè®®
        try:
            # ç®€åŒ–ï¼šä¼ å…¥åŸºç¡€å‚æ•°æ¨¡æ¿ï¼Œä¸ä½¿ç”¨å½“å‰åŸºçº¿åšå¯¹æ¯”
            group_llm = self._get_llm_group_summary_and_params(results, base_params, history=version_history)
            optimized_params = group_llm.get("suggested_params", {}) or {}
            reasoning = group_llm.get("reasoning", "") or ""
            summary = group_llm.get("group_summary") or ""
            sample_assessments = group_llm.get("sample_assessments", {}) or {}
            
            # å¦‚æœæ²¡æœ‰summaryï¼Œä½¿ç”¨é»˜è®¤æ€»ç»“
            if not summary:
                summary = self._summarize_batch(results, base_params, optimized_params, sample_assessments)
            
            # å¦‚æœLLMæ²¡æœ‰æä¾›æœ‰æ•ˆå»ºè®®ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°
            if not optimized_params and not reasoning:
                optimized_params = {}
                reasoning = "LLMæœªæä¾›å‚æ•°å»ºè®®ï¼Œä¿æŒé»˜è®¤å‚æ•°"
                
        except Exception as e:
            print(f"âš ï¸ ç»„çº§LLMæ€»ç»“/å‚æ•°å»ºè®®å¤±è´¥ï¼Œä½¿ç”¨å›é€€é€»è¾‘: {str(e)}")
            # å›é€€ï¼šä½¿ç”¨é»˜è®¤å‚æ•°
            optimized_params = {}
            reasoning = "LLMåˆ†æå¤±è´¥ï¼Œä¿æŒé»˜è®¤å‚æ•°"
            summary = self._summarize_batch(results, effective_params, optimized_params, {})

        # è®¡ç®—ä¸‹æ¬¡è¿­ä»£çš„å‚æ•°ï¼šç›´æ¥åˆå¹¶ LLM å»ºè®®ï¼ˆä¸åšå®æ—¶å·®å¼‚è¿‡æ»¤ï¼‰
        next_params = effective_params.copy()
        if optimized_params:
            next_params.update(optimized_params)
            print(f"ğŸ“ˆ å‚æ•°è¿›åŒ–: {len(optimized_params)} ä¸ªå‚æ•°å°†æ›´æ–°")
        else:
            print(f"ğŸ“Š å‚æ•°ç¨³å®š: ä¿æŒå½“å‰é…ç½®")
            # æ— å»ºè®®æ—¶ä¿æŒåŸç†ç”±

        return {
            "samples": results,
            "default_params": base_params,            # ç³»ç»Ÿé»˜è®¤å‚æ•°ï¼ˆä¸å˜ï¼‰
            "current_params": effective_params,       # æœ¬æ¬¡æ‰§è¡Œä½¿ç”¨çš„å‚æ•°
            "optimized_params": optimized_params,     # ç›´æ¥è¿”å›LLMå»ºè®®ï¼ˆä¸åšå·®å¼‚è¿‡æ»¤ï¼‰
            "next_params": next_params,               # ä¸‹æ¬¡æ‰§è¡Œåº”ä½¿ç”¨çš„å‚æ•°
            "version": version,  # å½“å‰å‚æ•°ç‰ˆæœ¬å·
            "version_files": {  # ç‰ˆæœ¬åŒ–æ–‡ä»¶è·¯å¾„
                "versioned": str(params_file),
                "latest": str(params_file_latest)
            },
            "summary": summary,
            "reasoning": reasoning,
            "total": len(results),
            "success_count": sum(1 for r in results if r.get('success')),
        }
